{
  "best_metric": 1.9406269788742065,
  "best_model_checkpoint": "./model/checkpoint-384000",
  "epoch": 14.988290398126464,
  "eval_steps": 2000,
  "global_step": 384000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0195160031225605,
      "grad_norm": 3.122957944869995,
      "learning_rate": 4.996747332812907e-05,
      "loss": 2.4923,
      "step": 500
    },
    {
      "epoch": 0.039032006245121,
      "grad_norm": 1.4516063928604126,
      "learning_rate": 4.993494665625814e-05,
      "loss": 2.1928,
      "step": 1000
    },
    {
      "epoch": 0.0585480093676815,
      "grad_norm": 0.7107067108154297,
      "learning_rate": 4.99024199843872e-05,
      "loss": 2.1414,
      "step": 1500
    },
    {
      "epoch": 0.078064012490242,
      "grad_norm": 0.5695063471794128,
      "learning_rate": 4.9869893312516264e-05,
      "loss": 2.1177,
      "step": 2000
    },
    {
      "epoch": 0.078064012490242,
      "eval_loss": 2.0959408283233643,
      "eval_runtime": 190.5658,
      "eval_samples_per_second": 39333.308,
      "eval_steps_per_second": 19.206,
      "step": 2000
    },
    {
      "epoch": 0.0975800156128025,
      "grad_norm": 0.57188880443573,
      "learning_rate": 4.983736664064533e-05,
      "loss": 2.103,
      "step": 2500
    },
    {
      "epoch": 0.117096018735363,
      "grad_norm": 0.5152796506881714,
      "learning_rate": 4.98048399687744e-05,
      "loss": 2.0918,
      "step": 3000
    },
    {
      "epoch": 0.1366120218579235,
      "grad_norm": 0.49864640831947327,
      "learning_rate": 4.977231329690346e-05,
      "loss": 2.0828,
      "step": 3500
    },
    {
      "epoch": 0.156128024980484,
      "grad_norm": 0.45265790820121765,
      "learning_rate": 4.973978662503253e-05,
      "loss": 2.0754,
      "step": 4000
    },
    {
      "epoch": 0.156128024980484,
      "eval_loss": 2.0587172508239746,
      "eval_runtime": 200.3894,
      "eval_samples_per_second": 37405.089,
      "eval_steps_per_second": 18.264,
      "step": 4000
    },
    {
      "epoch": 0.1756440281030445,
      "grad_norm": 0.443136066198349,
      "learning_rate": 4.9707259953161594e-05,
      "loss": 2.0681,
      "step": 4500
    },
    {
      "epoch": 0.195160031225605,
      "grad_norm": 0.4379871189594269,
      "learning_rate": 4.967473328129066e-05,
      "loss": 2.0633,
      "step": 5000
    },
    {
      "epoch": 0.21467603434816548,
      "grad_norm": 0.45649099349975586,
      "learning_rate": 4.964220660941973e-05,
      "loss": 2.0573,
      "step": 5500
    },
    {
      "epoch": 0.234192037470726,
      "grad_norm": 0.43458089232444763,
      "learning_rate": 4.9609679937548795e-05,
      "loss": 2.0532,
      "step": 6000
    },
    {
      "epoch": 0.234192037470726,
      "eval_loss": 2.0386083126068115,
      "eval_runtime": 198.8933,
      "eval_samples_per_second": 37686.454,
      "eval_steps_per_second": 18.402,
      "step": 6000
    },
    {
      "epoch": 0.2537080405932865,
      "grad_norm": 0.42730411887168884,
      "learning_rate": 4.9577153265677856e-05,
      "loss": 2.0493,
      "step": 6500
    },
    {
      "epoch": 0.273224043715847,
      "grad_norm": 0.441190242767334,
      "learning_rate": 4.954462659380692e-05,
      "loss": 2.0454,
      "step": 7000
    },
    {
      "epoch": 0.2927400468384075,
      "grad_norm": 0.4108950197696686,
      "learning_rate": 4.951209992193599e-05,
      "loss": 2.0424,
      "step": 7500
    },
    {
      "epoch": 0.312256049960968,
      "grad_norm": 0.4171789586544037,
      "learning_rate": 4.947957325006505e-05,
      "loss": 2.0397,
      "step": 8000
    },
    {
      "epoch": 0.312256049960968,
      "eval_loss": 2.0264792442321777,
      "eval_runtime": 202.3212,
      "eval_samples_per_second": 37047.941,
      "eval_steps_per_second": 18.09,
      "step": 8000
    },
    {
      "epoch": 0.3317720530835285,
      "grad_norm": 0.40969473123550415,
      "learning_rate": 4.9447046578194124e-05,
      "loss": 2.0365,
      "step": 8500
    },
    {
      "epoch": 0.351288056206089,
      "grad_norm": 0.40142300724983215,
      "learning_rate": 4.9414519906323185e-05,
      "loss": 2.0342,
      "step": 9000
    },
    {
      "epoch": 0.3708040593286495,
      "grad_norm": 0.4031660556793213,
      "learning_rate": 4.938199323445225e-05,
      "loss": 2.0319,
      "step": 9500
    },
    {
      "epoch": 0.39032006245121,
      "grad_norm": 0.3989976644515991,
      "learning_rate": 4.934946656258132e-05,
      "loss": 2.0294,
      "step": 10000
    },
    {
      "epoch": 0.39032006245121,
      "eval_loss": 2.0173919200897217,
      "eval_runtime": 205.8513,
      "eval_samples_per_second": 36412.618,
      "eval_steps_per_second": 17.78,
      "step": 10000
    },
    {
      "epoch": 0.4098360655737705,
      "grad_norm": 0.3931596577167511,
      "learning_rate": 4.9316939890710386e-05,
      "loss": 2.0273,
      "step": 10500
    },
    {
      "epoch": 0.42935206869633097,
      "grad_norm": 0.40611788630485535,
      "learning_rate": 4.928441321883945e-05,
      "loss": 2.0246,
      "step": 11000
    },
    {
      "epoch": 0.4488680718188915,
      "grad_norm": 0.39355242252349854,
      "learning_rate": 4.925188654696852e-05,
      "loss": 2.0236,
      "step": 11500
    },
    {
      "epoch": 0.468384074941452,
      "grad_norm": 0.37392011284828186,
      "learning_rate": 4.921942492844133e-05,
      "loss": 2.0222,
      "step": 12000
    },
    {
      "epoch": 0.468384074941452,
      "eval_loss": 2.0110249519348145,
      "eval_runtime": 198.5833,
      "eval_samples_per_second": 37745.29,
      "eval_steps_per_second": 18.431,
      "step": 12000
    },
    {
      "epoch": 0.4879000780640125,
      "grad_norm": 0.37118566036224365,
      "learning_rate": 4.918689825657039e-05,
      "loss": 2.0203,
      "step": 12500
    },
    {
      "epoch": 0.507416081186573,
      "grad_norm": 0.37772318720817566,
      "learning_rate": 4.9154371584699456e-05,
      "loss": 2.0191,
      "step": 13000
    },
    {
      "epoch": 0.5269320843091335,
      "grad_norm": 0.38172492384910583,
      "learning_rate": 4.9121844912828523e-05,
      "loss": 2.0183,
      "step": 13500
    },
    {
      "epoch": 0.546448087431694,
      "grad_norm": 0.37140506505966187,
      "learning_rate": 4.908931824095759e-05,
      "loss": 2.0163,
      "step": 14000
    },
    {
      "epoch": 0.546448087431694,
      "eval_loss": 2.005218744277954,
      "eval_runtime": 201.9425,
      "eval_samples_per_second": 37117.414,
      "eval_steps_per_second": 18.124,
      "step": 14000
    },
    {
      "epoch": 0.5659640905542545,
      "grad_norm": 0.3656243085861206,
      "learning_rate": 4.905679156908665e-05,
      "loss": 2.0144,
      "step": 14500
    },
    {
      "epoch": 0.585480093676815,
      "grad_norm": 0.35828086733818054,
      "learning_rate": 4.902426489721572e-05,
      "loss": 2.0131,
      "step": 15000
    },
    {
      "epoch": 0.6049960967993755,
      "grad_norm": 0.36928725242614746,
      "learning_rate": 4.8991738225344785e-05,
      "loss": 2.0133,
      "step": 15500
    },
    {
      "epoch": 0.624512099921936,
      "grad_norm": 0.3945801258087158,
      "learning_rate": 4.895927660681759e-05,
      "loss": 2.0116,
      "step": 16000
    },
    {
      "epoch": 0.624512099921936,
      "eval_loss": 2.0010037422180176,
      "eval_runtime": 199.7186,
      "eval_samples_per_second": 37530.718,
      "eval_steps_per_second": 18.326,
      "step": 16000
    },
    {
      "epoch": 0.6440281030444965,
      "grad_norm": 0.38875532150268555,
      "learning_rate": 4.892674993494666e-05,
      "loss": 2.0097,
      "step": 16500
    },
    {
      "epoch": 0.663544106167057,
      "grad_norm": 0.34597304463386536,
      "learning_rate": 4.889422326307572e-05,
      "loss": 2.0088,
      "step": 17000
    },
    {
      "epoch": 0.6830601092896175,
      "grad_norm": 0.35616540908813477,
      "learning_rate": 4.8861696591204795e-05,
      "loss": 2.0082,
      "step": 17500
    },
    {
      "epoch": 0.702576112412178,
      "grad_norm": 0.3575775921344757,
      "learning_rate": 4.8829234972677596e-05,
      "loss": 2.0078,
      "step": 18000
    },
    {
      "epoch": 0.702576112412178,
      "eval_loss": 1.9970595836639404,
      "eval_runtime": 196.9249,
      "eval_samples_per_second": 38063.162,
      "eval_steps_per_second": 18.586,
      "step": 18000
    },
    {
      "epoch": 0.7220921155347385,
      "grad_norm": 0.3551348149776459,
      "learning_rate": 4.879670830080666e-05,
      "loss": 2.0062,
      "step": 18500
    },
    {
      "epoch": 0.741608118657299,
      "grad_norm": 0.339083194732666,
      "learning_rate": 4.876418162893573e-05,
      "loss": 2.0052,
      "step": 19000
    },
    {
      "epoch": 0.7611241217798594,
      "grad_norm": 0.3451480269432068,
      "learning_rate": 4.873165495706479e-05,
      "loss": 2.004,
      "step": 19500
    },
    {
      "epoch": 0.78064012490242,
      "grad_norm": 0.3343638777732849,
      "learning_rate": 4.86991933385376e-05,
      "loss": 2.0038,
      "step": 20000
    },
    {
      "epoch": 0.78064012490242,
      "eval_loss": 1.993348479270935,
      "eval_runtime": 196.4298,
      "eval_samples_per_second": 38159.097,
      "eval_steps_per_second": 18.633,
      "step": 20000
    },
    {
      "epoch": 0.8001561280249805,
      "grad_norm": 0.3327179551124573,
      "learning_rate": 4.866666666666667e-05,
      "loss": 2.0026,
      "step": 20500
    },
    {
      "epoch": 0.819672131147541,
      "grad_norm": 0.33092111349105835,
      "learning_rate": 4.863413999479573e-05,
      "loss": 2.0019,
      "step": 21000
    },
    {
      "epoch": 0.8391881342701015,
      "grad_norm": 0.3385249376296997,
      "learning_rate": 4.86016133229248e-05,
      "loss": 2.0018,
      "step": 21500
    },
    {
      "epoch": 0.8587041373926619,
      "grad_norm": 0.3353046476840973,
      "learning_rate": 4.856915170439761e-05,
      "loss": 2.0007,
      "step": 22000
    },
    {
      "epoch": 0.8587041373926619,
      "eval_loss": 1.9904731512069702,
      "eval_runtime": 196.5936,
      "eval_samples_per_second": 38127.306,
      "eval_steps_per_second": 18.617,
      "step": 22000
    },
    {
      "epoch": 0.8782201405152225,
      "grad_norm": 0.36456117033958435,
      "learning_rate": 4.8536625032526676e-05,
      "loss": 1.999,
      "step": 22500
    },
    {
      "epoch": 0.897736143637783,
      "grad_norm": 0.3194175362586975,
      "learning_rate": 4.850409836065574e-05,
      "loss": 1.9988,
      "step": 23000
    },
    {
      "epoch": 0.9172521467603435,
      "grad_norm": 0.33435314893722534,
      "learning_rate": 4.84715716887848e-05,
      "loss": 1.9988,
      "step": 23500
    },
    {
      "epoch": 0.936768149882904,
      "grad_norm": 0.3283773958683014,
      "learning_rate": 4.843911007025762e-05,
      "loss": 1.9979,
      "step": 24000
    },
    {
      "epoch": 0.936768149882904,
      "eval_loss": 1.988408088684082,
      "eval_runtime": 196.4076,
      "eval_samples_per_second": 38163.407,
      "eval_steps_per_second": 18.635,
      "step": 24000
    },
    {
      "epoch": 0.9562841530054644,
      "grad_norm": 0.33705636858940125,
      "learning_rate": 4.840658339838668e-05,
      "loss": 1.9979,
      "step": 24500
    },
    {
      "epoch": 0.975800156128025,
      "grad_norm": 0.3353055417537689,
      "learning_rate": 4.8374056726515745e-05,
      "loss": 1.9963,
      "step": 25000
    },
    {
      "epoch": 0.9953161592505855,
      "grad_norm": 0.32634517550468445,
      "learning_rate": 4.834153005464481e-05,
      "loss": 1.9964,
      "step": 25500
    },
    {
      "epoch": 1.014832162373146,
      "grad_norm": 0.3124525547027588,
      "learning_rate": 4.830900338277387e-05,
      "loss": 1.9947,
      "step": 26000
    },
    {
      "epoch": 1.014832162373146,
      "eval_loss": 1.9855693578720093,
      "eval_runtime": 197.9244,
      "eval_samples_per_second": 37870.949,
      "eval_steps_per_second": 18.492,
      "step": 26000
    },
    {
      "epoch": 1.0343481654957065,
      "grad_norm": 0.3213605284690857,
      "learning_rate": 4.827654176424669e-05,
      "loss": 1.9943,
      "step": 26500
    },
    {
      "epoch": 1.053864168618267,
      "grad_norm": 0.3215128481388092,
      "learning_rate": 4.824401509237575e-05,
      "loss": 1.9941,
      "step": 27000
    },
    {
      "epoch": 1.0733801717408276,
      "grad_norm": 0.34086406230926514,
      "learning_rate": 4.821148842050482e-05,
      "loss": 1.9939,
      "step": 27500
    },
    {
      "epoch": 1.092896174863388,
      "grad_norm": 0.3342283368110657,
      "learning_rate": 4.817896174863388e-05,
      "loss": 1.9926,
      "step": 28000
    },
    {
      "epoch": 1.092896174863388,
      "eval_loss": 1.9836268424987793,
      "eval_runtime": 196.3867,
      "eval_samples_per_second": 38167.473,
      "eval_steps_per_second": 18.637,
      "step": 28000
    },
    {
      "epoch": 1.1124121779859484,
      "grad_norm": 0.32063111662864685,
      "learning_rate": 4.814650013010669e-05,
      "loss": 1.9932,
      "step": 28500
    },
    {
      "epoch": 1.131928181108509,
      "grad_norm": 0.32330623269081116,
      "learning_rate": 4.811397345823576e-05,
      "loss": 1.9925,
      "step": 29000
    },
    {
      "epoch": 1.1514441842310694,
      "grad_norm": 0.3225805461406708,
      "learning_rate": 4.808144678636482e-05,
      "loss": 1.992,
      "step": 29500
    },
    {
      "epoch": 1.17096018735363,
      "grad_norm": 0.29989203810691833,
      "learning_rate": 4.804892011449389e-05,
      "loss": 1.9913,
      "step": 30000
    },
    {
      "epoch": 1.17096018735363,
      "eval_loss": 1.9816334247589111,
      "eval_runtime": 196.1559,
      "eval_samples_per_second": 38212.37,
      "eval_steps_per_second": 18.659,
      "step": 30000
    },
    {
      "epoch": 1.1904761904761905,
      "grad_norm": 0.3131512701511383,
      "learning_rate": 4.801645849596669e-05,
      "loss": 1.9912,
      "step": 30500
    },
    {
      "epoch": 1.209992193598751,
      "grad_norm": 0.3048893213272095,
      "learning_rate": 4.798393182409576e-05,
      "loss": 1.991,
      "step": 31000
    },
    {
      "epoch": 1.2295081967213115,
      "grad_norm": 0.32219284772872925,
      "learning_rate": 4.795140515222483e-05,
      "loss": 1.99,
      "step": 31500
    },
    {
      "epoch": 1.249024199843872,
      "grad_norm": 0.30142417550086975,
      "learning_rate": 4.791887848035389e-05,
      "loss": 1.9894,
      "step": 32000
    },
    {
      "epoch": 1.249024199843872,
      "eval_loss": 1.980258584022522,
      "eval_runtime": 197.2819,
      "eval_samples_per_second": 37994.269,
      "eval_steps_per_second": 18.552,
      "step": 32000
    },
    {
      "epoch": 1.2685402029664326,
      "grad_norm": 0.31933438777923584,
      "learning_rate": 4.78864168618267e-05,
      "loss": 1.9891,
      "step": 32500
    },
    {
      "epoch": 1.288056206088993,
      "grad_norm": 0.3099815249443054,
      "learning_rate": 4.785389018995576e-05,
      "loss": 1.9891,
      "step": 33000
    },
    {
      "epoch": 1.3075722092115534,
      "grad_norm": 0.35362663865089417,
      "learning_rate": 4.782136351808483e-05,
      "loss": 1.9885,
      "step": 33500
    },
    {
      "epoch": 1.327088212334114,
      "grad_norm": 0.2993011772632599,
      "learning_rate": 4.77888368462139e-05,
      "loss": 1.9881,
      "step": 34000
    },
    {
      "epoch": 1.327088212334114,
      "eval_loss": 1.978147268295288,
      "eval_runtime": 196.8698,
      "eval_samples_per_second": 38073.81,
      "eval_steps_per_second": 18.591,
      "step": 34000
    },
    {
      "epoch": 1.3466042154566744,
      "grad_norm": 0.2930052876472473,
      "learning_rate": 4.7756375227686706e-05,
      "loss": 1.988,
      "step": 34500
    },
    {
      "epoch": 1.366120218579235,
      "grad_norm": 0.3114643692970276,
      "learning_rate": 4.772384855581577e-05,
      "loss": 1.9874,
      "step": 35000
    },
    {
      "epoch": 1.3856362217017955,
      "grad_norm": 0.2897747755050659,
      "learning_rate": 4.769132188394484e-05,
      "loss": 1.9874,
      "step": 35500
    },
    {
      "epoch": 1.405152224824356,
      "grad_norm": 0.29915082454681396,
      "learning_rate": 4.76587952120739e-05,
      "loss": 1.987,
      "step": 36000
    },
    {
      "epoch": 1.405152224824356,
      "eval_loss": 1.9772323369979858,
      "eval_runtime": 196.8943,
      "eval_samples_per_second": 38069.066,
      "eval_steps_per_second": 18.589,
      "step": 36000
    },
    {
      "epoch": 1.4246682279469165,
      "grad_norm": 0.2914668321609497,
      "learning_rate": 4.7626333593546715e-05,
      "loss": 1.9859,
      "step": 36500
    },
    {
      "epoch": 1.444184231069477,
      "grad_norm": 0.32436230778694153,
      "learning_rate": 4.7593806921675776e-05,
      "loss": 1.986,
      "step": 37000
    },
    {
      "epoch": 1.4637002341920375,
      "grad_norm": 0.2997749447822571,
      "learning_rate": 4.756128024980484e-05,
      "loss": 1.9852,
      "step": 37500
    },
    {
      "epoch": 1.4832162373145978,
      "grad_norm": 0.2866840362548828,
      "learning_rate": 4.752875357793391e-05,
      "loss": 1.9851,
      "step": 38000
    },
    {
      "epoch": 1.4832162373145978,
      "eval_loss": 1.9761995077133179,
      "eval_runtime": 194.9715,
      "eval_samples_per_second": 38444.503,
      "eval_steps_per_second": 18.772,
      "step": 38000
    },
    {
      "epoch": 1.5027322404371586,
      "grad_norm": 0.3001147210597992,
      "learning_rate": 4.749629195940671e-05,
      "loss": 1.985,
      "step": 38500
    },
    {
      "epoch": 1.5222482435597189,
      "grad_norm": 0.29287824034690857,
      "learning_rate": 4.7463765287535785e-05,
      "loss": 1.9846,
      "step": 39000
    },
    {
      "epoch": 1.5417642466822796,
      "grad_norm": 0.2980237901210785,
      "learning_rate": 4.7431238615664845e-05,
      "loss": 1.9843,
      "step": 39500
    },
    {
      "epoch": 1.56128024980484,
      "grad_norm": 0.3122543692588806,
      "learning_rate": 4.739871194379391e-05,
      "loss": 1.984,
      "step": 40000
    },
    {
      "epoch": 1.56128024980484,
      "eval_loss": 1.9749032258987427,
      "eval_runtime": 194.8478,
      "eval_samples_per_second": 38468.909,
      "eval_steps_per_second": 18.784,
      "step": 40000
    },
    {
      "epoch": 1.5807962529274004,
      "grad_norm": 0.29022857546806335,
      "learning_rate": 4.736625032526672e-05,
      "loss": 1.9838,
      "step": 40500
    },
    {
      "epoch": 1.600312256049961,
      "grad_norm": 0.2839896082878113,
      "learning_rate": 4.733372365339579e-05,
      "loss": 1.9838,
      "step": 41000
    },
    {
      "epoch": 1.6198282591725215,
      "grad_norm": 0.2954927682876587,
      "learning_rate": 4.7301196981524855e-05,
      "loss": 1.9827,
      "step": 41500
    },
    {
      "epoch": 1.639344262295082,
      "grad_norm": 0.3103818893432617,
      "learning_rate": 4.7268670309653915e-05,
      "loss": 1.9823,
      "step": 42000
    },
    {
      "epoch": 1.639344262295082,
      "eval_loss": 1.9739927053451538,
      "eval_runtime": 195.308,
      "eval_samples_per_second": 38378.27,
      "eval_steps_per_second": 18.74,
      "step": 42000
    },
    {
      "epoch": 1.6588602654176423,
      "grad_norm": 0.28494253754615784,
      "learning_rate": 4.723620869112672e-05,
      "loss": 1.983,
      "step": 42500
    },
    {
      "epoch": 1.678376268540203,
      "grad_norm": 0.2775530517101288,
      "learning_rate": 4.720368201925579e-05,
      "loss": 1.9821,
      "step": 43000
    },
    {
      "epoch": 1.6978922716627634,
      "grad_norm": 0.2952769696712494,
      "learning_rate": 4.717115534738486e-05,
      "loss": 1.9817,
      "step": 43500
    },
    {
      "epoch": 1.717408274785324,
      "grad_norm": 0.2709977626800537,
      "learning_rate": 4.7138628675513925e-05,
      "loss": 1.9814,
      "step": 44000
    },
    {
      "epoch": 1.717408274785324,
      "eval_loss": 1.972579002380371,
      "eval_runtime": 195.5234,
      "eval_samples_per_second": 38335.987,
      "eval_steps_per_second": 18.719,
      "step": 44000
    },
    {
      "epoch": 1.7369242779078844,
      "grad_norm": 0.2863213121891022,
      "learning_rate": 4.710616705698673e-05,
      "loss": 1.9813,
      "step": 44500
    },
    {
      "epoch": 1.756440281030445,
      "grad_norm": 0.2875043749809265,
      "learning_rate": 4.70736403851158e-05,
      "loss": 1.9811,
      "step": 45000
    },
    {
      "epoch": 1.7759562841530054,
      "grad_norm": 0.2734909951686859,
      "learning_rate": 4.704111371324486e-05,
      "loss": 1.9806,
      "step": 45500
    },
    {
      "epoch": 1.795472287275566,
      "grad_norm": 0.2794097363948822,
      "learning_rate": 4.700858704137393e-05,
      "loss": 1.9806,
      "step": 46000
    },
    {
      "epoch": 1.795472287275566,
      "eval_loss": 1.9718137979507446,
      "eval_runtime": 194.6594,
      "eval_samples_per_second": 38506.135,
      "eval_steps_per_second": 18.802,
      "step": 46000
    },
    {
      "epoch": 1.8149882903981265,
      "grad_norm": 0.29007482528686523,
      "learning_rate": 4.6976125422846736e-05,
      "loss": 1.9804,
      "step": 46500
    },
    {
      "epoch": 1.834504293520687,
      "grad_norm": 0.30173981189727783,
      "learning_rate": 4.69435987509758e-05,
      "loss": 1.9807,
      "step": 47000
    },
    {
      "epoch": 1.8540202966432475,
      "grad_norm": 0.2654847800731659,
      "learning_rate": 4.691107207910487e-05,
      "loss": 1.9805,
      "step": 47500
    },
    {
      "epoch": 1.8735362997658078,
      "grad_norm": 0.2713202238082886,
      "learning_rate": 4.687854540723393e-05,
      "loss": 1.9799,
      "step": 48000
    },
    {
      "epoch": 1.8735362997658078,
      "eval_loss": 1.9705313444137573,
      "eval_runtime": 195.2467,
      "eval_samples_per_second": 38390.321,
      "eval_steps_per_second": 18.746,
      "step": 48000
    },
    {
      "epoch": 1.8930523028883686,
      "grad_norm": 0.27385255694389343,
      "learning_rate": 4.684608378870674e-05,
      "loss": 1.9799,
      "step": 48500
    },
    {
      "epoch": 1.9125683060109289,
      "grad_norm": 0.27211207151412964,
      "learning_rate": 4.681355711683581e-05,
      "loss": 1.9799,
      "step": 49000
    },
    {
      "epoch": 1.9320843091334896,
      "grad_norm": 0.28217339515686035,
      "learning_rate": 4.678103044496487e-05,
      "loss": 1.9791,
      "step": 49500
    },
    {
      "epoch": 1.95160031225605,
      "grad_norm": 0.27958446741104126,
      "learning_rate": 4.674850377309394e-05,
      "loss": 1.9792,
      "step": 50000
    },
    {
      "epoch": 1.95160031225605,
      "eval_loss": 1.970180869102478,
      "eval_runtime": 194.6928,
      "eval_samples_per_second": 38499.531,
      "eval_steps_per_second": 18.799,
      "step": 50000
    },
    {
      "epoch": 1.9711163153786104,
      "grad_norm": 0.26509740948677063,
      "learning_rate": 4.671604215456675e-05,
      "loss": 1.9791,
      "step": 50500
    },
    {
      "epoch": 1.990632318501171,
      "grad_norm": 0.2885645627975464,
      "learning_rate": 4.668351548269581e-05,
      "loss": 1.9791,
      "step": 51000
    },
    {
      "epoch": 2.0101483216237312,
      "grad_norm": 0.28550589084625244,
      "learning_rate": 4.665098881082488e-05,
      "loss": 1.9774,
      "step": 51500
    },
    {
      "epoch": 2.029664324746292,
      "grad_norm": 0.2747800946235657,
      "learning_rate": 4.661846213895394e-05,
      "loss": 1.9776,
      "step": 52000
    },
    {
      "epoch": 2.029664324746292,
      "eval_loss": 1.9689284563064575,
      "eval_runtime": 195.0841,
      "eval_samples_per_second": 38422.312,
      "eval_steps_per_second": 18.761,
      "step": 52000
    },
    {
      "epoch": 2.0491803278688523,
      "grad_norm": 0.2728251516819,
      "learning_rate": 4.658600052042675e-05,
      "loss": 1.9775,
      "step": 52500
    },
    {
      "epoch": 2.068696330991413,
      "grad_norm": 0.28024840354919434,
      "learning_rate": 4.655347384855582e-05,
      "loss": 1.9778,
      "step": 53000
    },
    {
      "epoch": 2.0882123341139733,
      "grad_norm": 0.283512145280838,
      "learning_rate": 4.652094717668488e-05,
      "loss": 1.9781,
      "step": 53500
    },
    {
      "epoch": 2.107728337236534,
      "grad_norm": 0.26963010430336,
      "learning_rate": 4.648842050481395e-05,
      "loss": 1.9773,
      "step": 54000
    },
    {
      "epoch": 2.107728337236534,
      "eval_loss": 1.9682329893112183,
      "eval_runtime": 193.8253,
      "eval_samples_per_second": 38671.847,
      "eval_steps_per_second": 18.883,
      "step": 54000
    },
    {
      "epoch": 2.1272443403590944,
      "grad_norm": 0.2804141640663147,
      "learning_rate": 4.645595888628676e-05,
      "loss": 1.9769,
      "step": 54500
    },
    {
      "epoch": 2.146760343481655,
      "grad_norm": 0.26950305700302124,
      "learning_rate": 4.642343221441583e-05,
      "loss": 1.9762,
      "step": 55000
    },
    {
      "epoch": 2.1662763466042154,
      "grad_norm": 0.27580857276916504,
      "learning_rate": 4.639090554254489e-05,
      "loss": 1.9763,
      "step": 55500
    },
    {
      "epoch": 2.185792349726776,
      "grad_norm": 0.2785169184207916,
      "learning_rate": 4.6358378870673955e-05,
      "loss": 1.976,
      "step": 56000
    },
    {
      "epoch": 2.185792349726776,
      "eval_loss": 1.9677672386169434,
      "eval_runtime": 193.673,
      "eval_samples_per_second": 38702.262,
      "eval_steps_per_second": 18.898,
      "step": 56000
    },
    {
      "epoch": 2.2053083528493365,
      "grad_norm": 0.2681235373020172,
      "learning_rate": 4.632591725214676e-05,
      "loss": 1.9759,
      "step": 56500
    },
    {
      "epoch": 2.2248243559718968,
      "grad_norm": 0.2752659022808075,
      "learning_rate": 4.629339058027583e-05,
      "loss": 1.9758,
      "step": 57000
    },
    {
      "epoch": 2.2443403590944575,
      "grad_norm": 0.2662525773048401,
      "learning_rate": 4.62608639084049e-05,
      "loss": 1.9758,
      "step": 57500
    },
    {
      "epoch": 2.263856362217018,
      "grad_norm": 0.2706616520881653,
      "learning_rate": 4.622833723653396e-05,
      "loss": 1.9757,
      "step": 58000
    },
    {
      "epoch": 2.263856362217018,
      "eval_loss": 1.9670616388320923,
      "eval_runtime": 194.609,
      "eval_samples_per_second": 38516.109,
      "eval_steps_per_second": 18.807,
      "step": 58000
    },
    {
      "epoch": 2.2833723653395785,
      "grad_norm": 0.2902510166168213,
      "learning_rate": 4.6195875618006766e-05,
      "loss": 1.9752,
      "step": 58500
    },
    {
      "epoch": 2.302888368462139,
      "grad_norm": 0.26895785331726074,
      "learning_rate": 4.616334894613583e-05,
      "loss": 1.975,
      "step": 59000
    },
    {
      "epoch": 2.3224043715846996,
      "grad_norm": 0.2650759816169739,
      "learning_rate": 4.61308222742649e-05,
      "loss": 1.9748,
      "step": 59500
    },
    {
      "epoch": 2.34192037470726,
      "grad_norm": 0.25868621468544006,
      "learning_rate": 4.609829560239397e-05,
      "loss": 1.9748,
      "step": 60000
    },
    {
      "epoch": 2.34192037470726,
      "eval_loss": 1.9666450023651123,
      "eval_runtime": 192.9206,
      "eval_samples_per_second": 38853.199,
      "eval_steps_per_second": 18.972,
      "step": 60000
    },
    {
      "epoch": 2.3614363778298206,
      "grad_norm": 0.2819772958755493,
      "learning_rate": 4.6065833983866775e-05,
      "loss": 1.9748,
      "step": 60500
    },
    {
      "epoch": 2.380952380952381,
      "grad_norm": 0.26488882303237915,
      "learning_rate": 4.6033307311995836e-05,
      "loss": 1.9746,
      "step": 61000
    },
    {
      "epoch": 2.4004683840749417,
      "grad_norm": 0.28564685583114624,
      "learning_rate": 4.60007806401249e-05,
      "loss": 1.9745,
      "step": 61500
    },
    {
      "epoch": 2.419984387197502,
      "grad_norm": 0.2720264196395874,
      "learning_rate": 4.596825396825397e-05,
      "loss": 1.9742,
      "step": 62000
    },
    {
      "epoch": 2.419984387197502,
      "eval_loss": 1.9657310247421265,
      "eval_runtime": 194.5493,
      "eval_samples_per_second": 38527.932,
      "eval_steps_per_second": 18.813,
      "step": 62000
    },
    {
      "epoch": 2.4395003903200623,
      "grad_norm": 0.262462317943573,
      "learning_rate": 4.593579234972678e-05,
      "loss": 1.974,
      "step": 62500
    },
    {
      "epoch": 2.459016393442623,
      "grad_norm": 0.27500295639038086,
      "learning_rate": 4.5903265677855845e-05,
      "loss": 1.9744,
      "step": 63000
    },
    {
      "epoch": 2.4785323965651833,
      "grad_norm": 0.26308539509773254,
      "learning_rate": 4.5870739005984906e-05,
      "loss": 1.9738,
      "step": 63500
    },
    {
      "epoch": 2.498048399687744,
      "grad_norm": 0.2641944885253906,
      "learning_rate": 4.583821233411398e-05,
      "loss": 1.9737,
      "step": 64000
    },
    {
      "epoch": 2.498048399687744,
      "eval_loss": 1.9650321006774902,
      "eval_runtime": 191.8899,
      "eval_samples_per_second": 39061.899,
      "eval_steps_per_second": 19.073,
      "step": 64000
    },
    {
      "epoch": 2.5175644028103044,
      "grad_norm": 0.26661017537117004,
      "learning_rate": 4.580575071558678e-05,
      "loss": 1.9734,
      "step": 64500
    },
    {
      "epoch": 2.537080405932865,
      "grad_norm": 0.27927789092063904,
      "learning_rate": 4.577322404371585e-05,
      "loss": 1.9734,
      "step": 65000
    },
    {
      "epoch": 2.5565964090554254,
      "grad_norm": 0.2637409567832947,
      "learning_rate": 4.5740697371844915e-05,
      "loss": 1.973,
      "step": 65500
    },
    {
      "epoch": 2.576112412177986,
      "grad_norm": 0.26044610142707825,
      "learning_rate": 4.570817069997398e-05,
      "loss": 1.9725,
      "step": 66000
    },
    {
      "epoch": 2.576112412177986,
      "eval_loss": 1.96433687210083,
      "eval_runtime": 194.1262,
      "eval_samples_per_second": 38611.898,
      "eval_steps_per_second": 18.854,
      "step": 66000
    },
    {
      "epoch": 2.5956284153005464,
      "grad_norm": 0.25424671173095703,
      "learning_rate": 4.567577413479053e-05,
      "loss": 1.972,
      "step": 66500
    },
    {
      "epoch": 2.6151444184231067,
      "grad_norm": 0.2703247666358948,
      "learning_rate": 4.56432474629196e-05,
      "loss": 1.9729,
      "step": 67000
    },
    {
      "epoch": 2.6346604215456675,
      "grad_norm": 0.2608671486377716,
      "learning_rate": 4.561072079104866e-05,
      "loss": 1.9727,
      "step": 67500
    },
    {
      "epoch": 2.654176424668228,
      "grad_norm": 0.2667979300022125,
      "learning_rate": 4.557819411917773e-05,
      "loss": 1.9727,
      "step": 68000
    },
    {
      "epoch": 2.654176424668228,
      "eval_loss": 1.9641366004943848,
      "eval_runtime": 193.3488,
      "eval_samples_per_second": 38767.153,
      "eval_steps_per_second": 18.93,
      "step": 68000
    },
    {
      "epoch": 2.6736924277907885,
      "grad_norm": 0.2595534324645996,
      "learning_rate": 4.554566744730679e-05,
      "loss": 1.9725,
      "step": 68500
    },
    {
      "epoch": 2.693208430913349,
      "grad_norm": 0.2604619860649109,
      "learning_rate": 4.551314077543586e-05,
      "loss": 1.9722,
      "step": 69000
    },
    {
      "epoch": 2.7127244340359096,
      "grad_norm": 0.2738838493824005,
      "learning_rate": 4.548061410356493e-05,
      "loss": 1.9717,
      "step": 69500
    },
    {
      "epoch": 2.73224043715847,
      "grad_norm": 0.2718493342399597,
      "learning_rate": 4.5448087431693995e-05,
      "loss": 1.9724,
      "step": 70000
    },
    {
      "epoch": 2.73224043715847,
      "eval_loss": 1.9636871814727783,
      "eval_runtime": 193.9899,
      "eval_samples_per_second": 38639.043,
      "eval_steps_per_second": 18.867,
      "step": 70000
    },
    {
      "epoch": 2.7517564402810306,
      "grad_norm": 0.2723293900489807,
      "learning_rate": 4.54156258131668e-05,
      "loss": 1.9718,
      "step": 70500
    },
    {
      "epoch": 2.771272443403591,
      "grad_norm": 0.2616344392299652,
      "learning_rate": 4.538309914129586e-05,
      "loss": 1.9718,
      "step": 71000
    },
    {
      "epoch": 2.790788446526151,
      "grad_norm": 0.25870758295059204,
      "learning_rate": 4.535057246942493e-05,
      "loss": 1.9719,
      "step": 71500
    },
    {
      "epoch": 2.810304449648712,
      "grad_norm": 0.2620893716812134,
      "learning_rate": 4.5318045797554e-05,
      "loss": 1.9715,
      "step": 72000
    },
    {
      "epoch": 2.810304449648712,
      "eval_loss": 1.9628063440322876,
      "eval_runtime": 194.921,
      "eval_samples_per_second": 38454.472,
      "eval_steps_per_second": 18.777,
      "step": 72000
    },
    {
      "epoch": 2.8298204527712727,
      "grad_norm": 0.2601514458656311,
      "learning_rate": 4.5285584179026805e-05,
      "loss": 1.9713,
      "step": 72500
    },
    {
      "epoch": 2.849336455893833,
      "grad_norm": 0.25777682662010193,
      "learning_rate": 4.525305750715587e-05,
      "loss": 1.9703,
      "step": 73000
    },
    {
      "epoch": 2.8688524590163933,
      "grad_norm": 0.2628701329231262,
      "learning_rate": 4.522053083528493e-05,
      "loss": 1.9706,
      "step": 73500
    },
    {
      "epoch": 2.888368462138954,
      "grad_norm": 0.25841978192329407,
      "learning_rate": 4.5188004163414e-05,
      "loss": 1.9716,
      "step": 74000
    },
    {
      "epoch": 2.888368462138954,
      "eval_loss": 1.9623699188232422,
      "eval_runtime": 194.0693,
      "eval_samples_per_second": 38623.235,
      "eval_steps_per_second": 18.859,
      "step": 74000
    },
    {
      "epoch": 2.9078844652615143,
      "grad_norm": 0.2570260167121887,
      "learning_rate": 4.515554254488681e-05,
      "loss": 1.971,
      "step": 74500
    },
    {
      "epoch": 2.927400468384075,
      "grad_norm": 0.2654489576816559,
      "learning_rate": 4.5123015873015875e-05,
      "loss": 1.9705,
      "step": 75000
    },
    {
      "epoch": 2.9469164715066354,
      "grad_norm": 0.2693893015384674,
      "learning_rate": 4.509048920114494e-05,
      "loss": 1.9708,
      "step": 75500
    },
    {
      "epoch": 2.9664324746291957,
      "grad_norm": 0.253152996301651,
      "learning_rate": 4.5057962529274e-05,
      "loss": 1.9701,
      "step": 76000
    },
    {
      "epoch": 2.9664324746291957,
      "eval_loss": 1.9620568752288818,
      "eval_runtime": 194.3649,
      "eval_samples_per_second": 38564.479,
      "eval_steps_per_second": 18.831,
      "step": 76000
    },
    {
      "epoch": 2.9859484777517564,
      "grad_norm": 0.2508927583694458,
      "learning_rate": 4.502550091074682e-05,
      "loss": 1.9703,
      "step": 76500
    },
    {
      "epoch": 3.0054644808743167,
      "grad_norm": 0.245570570230484,
      "learning_rate": 4.499297423887588e-05,
      "loss": 1.9697,
      "step": 77000
    },
    {
      "epoch": 3.0249804839968775,
      "grad_norm": 0.25711789727211,
      "learning_rate": 4.4960512620348686e-05,
      "loss": 1.9695,
      "step": 77500
    },
    {
      "epoch": 3.0444964871194378,
      "grad_norm": 0.26125043630599976,
      "learning_rate": 4.492798594847775e-05,
      "loss": 1.9697,
      "step": 78000
    },
    {
      "epoch": 3.0444964871194378,
      "eval_loss": 1.9616302251815796,
      "eval_runtime": 193.1569,
      "eval_samples_per_second": 38805.66,
      "eval_steps_per_second": 18.948,
      "step": 78000
    },
    {
      "epoch": 3.0640124902419985,
      "grad_norm": 0.2565791606903076,
      "learning_rate": 4.489545927660682e-05,
      "loss": 1.969,
      "step": 78500
    },
    {
      "epoch": 3.083528493364559,
      "grad_norm": 0.28744304180145264,
      "learning_rate": 4.486293260473589e-05,
      "loss": 1.9695,
      "step": 79000
    },
    {
      "epoch": 3.1030444964871196,
      "grad_norm": 0.2688194215297699,
      "learning_rate": 4.483040593286495e-05,
      "loss": 1.97,
      "step": 79500
    },
    {
      "epoch": 3.12256049960968,
      "grad_norm": 0.25316527485847473,
      "learning_rate": 4.479787926099402e-05,
      "loss": 1.9692,
      "step": 80000
    },
    {
      "epoch": 3.12256049960968,
      "eval_loss": 1.9611194133758545,
      "eval_runtime": 193.8693,
      "eval_samples_per_second": 38663.079,
      "eval_steps_per_second": 18.879,
      "step": 80000
    },
    {
      "epoch": 3.1420765027322406,
      "grad_norm": 0.2732381224632263,
      "learning_rate": 4.476541764246682e-05,
      "loss": 1.969,
      "step": 80500
    },
    {
      "epoch": 3.161592505854801,
      "grad_norm": 0.25695449113845825,
      "learning_rate": 4.473289097059589e-05,
      "loss": 1.9691,
      "step": 81000
    },
    {
      "epoch": 3.1811085089773616,
      "grad_norm": 0.2666673958301544,
      "learning_rate": 4.470036429872496e-05,
      "loss": 1.9691,
      "step": 81500
    },
    {
      "epoch": 3.200624512099922,
      "grad_norm": 0.24829219281673431,
      "learning_rate": 4.466783762685402e-05,
      "loss": 1.9686,
      "step": 82000
    },
    {
      "epoch": 3.200624512099922,
      "eval_loss": 1.9608956575393677,
      "eval_runtime": 194.5216,
      "eval_samples_per_second": 38533.426,
      "eval_steps_per_second": 18.815,
      "step": 82000
    },
    {
      "epoch": 3.2201405152224822,
      "grad_norm": 0.2579670548439026,
      "learning_rate": 4.463531095498309e-05,
      "loss": 1.9688,
      "step": 82500
    },
    {
      "epoch": 3.239656518345043,
      "grad_norm": 0.25374871492385864,
      "learning_rate": 4.460278428311215e-05,
      "loss": 1.9688,
      "step": 83000
    },
    {
      "epoch": 3.2591725214676033,
      "grad_norm": 0.25646743178367615,
      "learning_rate": 4.457025761124122e-05,
      "loss": 1.9685,
      "step": 83500
    },
    {
      "epoch": 3.278688524590164,
      "grad_norm": 0.2521093189716339,
      "learning_rate": 4.4537730939370287e-05,
      "loss": 1.9688,
      "step": 84000
    },
    {
      "epoch": 3.278688524590164,
      "eval_loss": 1.960000991821289,
      "eval_runtime": 194.0107,
      "eval_samples_per_second": 38634.9,
      "eval_steps_per_second": 18.865,
      "step": 84000
    },
    {
      "epoch": 3.2982045277127243,
      "grad_norm": 0.2482403814792633,
      "learning_rate": 4.4505269320843095e-05,
      "loss": 1.9689,
      "step": 84500
    },
    {
      "epoch": 3.317720530835285,
      "grad_norm": 0.2526981830596924,
      "learning_rate": 4.44728077023159e-05,
      "loss": 1.9681,
      "step": 85000
    },
    {
      "epoch": 3.3372365339578454,
      "grad_norm": 0.2499542385339737,
      "learning_rate": 4.444028103044497e-05,
      "loss": 1.9673,
      "step": 85500
    },
    {
      "epoch": 3.356752537080406,
      "grad_norm": 0.24928849935531616,
      "learning_rate": 4.440775435857403e-05,
      "loss": 1.9683,
      "step": 86000
    },
    {
      "epoch": 3.356752537080406,
      "eval_loss": 1.959863543510437,
      "eval_runtime": 191.9247,
      "eval_samples_per_second": 39054.819,
      "eval_steps_per_second": 19.07,
      "step": 86000
    },
    {
      "epoch": 3.3762685402029664,
      "grad_norm": 0.2500821053981781,
      "learning_rate": 4.43752276867031e-05,
      "loss": 1.9678,
      "step": 86500
    },
    {
      "epoch": 3.3957845433255267,
      "grad_norm": 0.24648654460906982,
      "learning_rate": 4.4342701014832164e-05,
      "loss": 1.968,
      "step": 87000
    },
    {
      "epoch": 3.4153005464480874,
      "grad_norm": 0.2567470967769623,
      "learning_rate": 4.431023939630497e-05,
      "loss": 1.9683,
      "step": 87500
    },
    {
      "epoch": 3.4348165495706477,
      "grad_norm": 0.26009100675582886,
      "learning_rate": 4.427771272443404e-05,
      "loss": 1.9678,
      "step": 88000
    },
    {
      "epoch": 3.4348165495706477,
      "eval_loss": 1.959531307220459,
      "eval_runtime": 193.2113,
      "eval_samples_per_second": 38794.744,
      "eval_steps_per_second": 18.943,
      "step": 88000
    },
    {
      "epoch": 3.4543325526932085,
      "grad_norm": 0.2523306608200073,
      "learning_rate": 4.424518605256311e-05,
      "loss": 1.9675,
      "step": 88500
    },
    {
      "epoch": 3.473848555815769,
      "grad_norm": 0.2704262137413025,
      "learning_rate": 4.421265938069217e-05,
      "loss": 1.9677,
      "step": 89000
    },
    {
      "epoch": 3.4933645589383295,
      "grad_norm": 0.2417251467704773,
      "learning_rate": 4.4180197762164975e-05,
      "loss": 1.9682,
      "step": 89500
    },
    {
      "epoch": 3.51288056206089,
      "grad_norm": 0.24748681485652924,
      "learning_rate": 4.414767109029404e-05,
      "loss": 1.9672,
      "step": 90000
    },
    {
      "epoch": 3.51288056206089,
      "eval_loss": 1.9593089818954468,
      "eval_runtime": 193.435,
      "eval_samples_per_second": 38749.872,
      "eval_steps_per_second": 18.921,
      "step": 90000
    },
    {
      "epoch": 3.5323965651834506,
      "grad_norm": 0.25968533754348755,
      "learning_rate": 4.411514441842311e-05,
      "loss": 1.9664,
      "step": 90500
    },
    {
      "epoch": 3.551912568306011,
      "grad_norm": 0.23944182693958282,
      "learning_rate": 4.408261774655218e-05,
      "loss": 1.9676,
      "step": 91000
    },
    {
      "epoch": 3.571428571428571,
      "grad_norm": 0.2568749487400055,
      "learning_rate": 4.4050091074681244e-05,
      "loss": 1.9677,
      "step": 91500
    },
    {
      "epoch": 3.590944574551132,
      "grad_norm": 0.264665812253952,
      "learning_rate": 4.4017564402810304e-05,
      "loss": 1.9673,
      "step": 92000
    },
    {
      "epoch": 3.590944574551132,
      "eval_loss": 1.9586576223373413,
      "eval_runtime": 194.0769,
      "eval_samples_per_second": 38621.709,
      "eval_steps_per_second": 18.859,
      "step": 92000
    },
    {
      "epoch": 3.6104605776736927,
      "grad_norm": 0.24741646647453308,
      "learning_rate": 4.398503773093937e-05,
      "loss": 1.9664,
      "step": 92500
    },
    {
      "epoch": 3.629976580796253,
      "grad_norm": 0.254300057888031,
      "learning_rate": 4.395251105906844e-05,
      "loss": 1.9673,
      "step": 93000
    },
    {
      "epoch": 3.6494925839188133,
      "grad_norm": 0.25161653757095337,
      "learning_rate": 4.392004944054125e-05,
      "loss": 1.9669,
      "step": 93500
    },
    {
      "epoch": 3.669008587041374,
      "grad_norm": 0.24592776596546173,
      "learning_rate": 4.3887522768670314e-05,
      "loss": 1.9664,
      "step": 94000
    },
    {
      "epoch": 3.669008587041374,
      "eval_loss": 1.9583189487457275,
      "eval_runtime": 193.0452,
      "eval_samples_per_second": 38828.133,
      "eval_steps_per_second": 18.959,
      "step": 94000
    },
    {
      "epoch": 3.6885245901639343,
      "grad_norm": 0.24786044657230377,
      "learning_rate": 4.3855061150143115e-05,
      "loss": 1.9666,
      "step": 94500
    },
    {
      "epoch": 3.708040593286495,
      "grad_norm": 0.2574827969074249,
      "learning_rate": 4.382253447827219e-05,
      "loss": 1.9671,
      "step": 95000
    },
    {
      "epoch": 3.7275565964090553,
      "grad_norm": 0.25978997349739075,
      "learning_rate": 4.379000780640125e-05,
      "loss": 1.9667,
      "step": 95500
    },
    {
      "epoch": 3.747072599531616,
      "grad_norm": 0.2437395304441452,
      "learning_rate": 4.3757481134530317e-05,
      "loss": 1.9663,
      "step": 96000
    },
    {
      "epoch": 3.747072599531616,
      "eval_loss": 1.9580662250518799,
      "eval_runtime": 194.0323,
      "eval_samples_per_second": 38630.587,
      "eval_steps_per_second": 18.863,
      "step": 96000
    },
    {
      "epoch": 3.7665886026541764,
      "grad_norm": 0.2368314266204834,
      "learning_rate": 4.3724954462659384e-05,
      "loss": 1.9663,
      "step": 96500
    },
    {
      "epoch": 3.786104605776737,
      "grad_norm": 0.24392582476139069,
      "learning_rate": 4.3692492844132185e-05,
      "loss": 1.9658,
      "step": 97000
    },
    {
      "epoch": 3.8056206088992974,
      "grad_norm": 0.2554527819156647,
      "learning_rate": 4.365996617226126e-05,
      "loss": 1.966,
      "step": 97500
    },
    {
      "epoch": 3.8251366120218577,
      "grad_norm": 0.25090402364730835,
      "learning_rate": 4.362743950039032e-05,
      "loss": 1.9662,
      "step": 98000
    },
    {
      "epoch": 3.8251366120218577,
      "eval_loss": 1.957561731338501,
      "eval_runtime": 192.8394,
      "eval_samples_per_second": 38869.552,
      "eval_steps_per_second": 18.98,
      "step": 98000
    },
    {
      "epoch": 3.8446526151444185,
      "grad_norm": 0.251189261674881,
      "learning_rate": 4.3594912828519387e-05,
      "loss": 1.9659,
      "step": 98500
    },
    {
      "epoch": 3.8641686182669788,
      "grad_norm": 0.24376805126667023,
      "learning_rate": 4.3562386156648454e-05,
      "loss": 1.966,
      "step": 99000
    },
    {
      "epoch": 3.8836846213895395,
      "grad_norm": 0.23891793191432953,
      "learning_rate": 4.352992453812126e-05,
      "loss": 1.9659,
      "step": 99500
    },
    {
      "epoch": 3.9032006245121,
      "grad_norm": 0.24031129479408264,
      "learning_rate": 4.349739786625033e-05,
      "loss": 1.9658,
      "step": 100000
    },
    {
      "epoch": 3.9032006245121,
      "eval_loss": 1.9574488401412964,
      "eval_runtime": 193.4795,
      "eval_samples_per_second": 38740.968,
      "eval_steps_per_second": 18.917,
      "step": 100000
    },
    {
      "epoch": 3.9227166276346606,
      "grad_norm": 0.2449970841407776,
      "learning_rate": 4.346487119437939e-05,
      "loss": 1.9656,
      "step": 100500
    },
    {
      "epoch": 3.942232630757221,
      "grad_norm": 0.24838027358055115,
      "learning_rate": 4.343234452250846e-05,
      "loss": 1.9661,
      "step": 101000
    },
    {
      "epoch": 3.9617486338797816,
      "grad_norm": 0.24417370557785034,
      "learning_rate": 4.3399882903981264e-05,
      "loss": 1.9655,
      "step": 101500
    },
    {
      "epoch": 3.981264637002342,
      "grad_norm": 0.24780608713626862,
      "learning_rate": 4.336735623211033e-05,
      "loss": 1.9655,
      "step": 102000
    },
    {
      "epoch": 3.981264637002342,
      "eval_loss": 1.9572244882583618,
      "eval_runtime": 194.1329,
      "eval_samples_per_second": 38610.569,
      "eval_steps_per_second": 18.853,
      "step": 102000
    },
    {
      "epoch": 4.000780640124902,
      "grad_norm": 0.2707180976867676,
      "learning_rate": 4.33348295602394e-05,
      "loss": 1.9653,
      "step": 102500
    },
    {
      "epoch": 4.0202966432474625,
      "grad_norm": 0.26037949323654175,
      "learning_rate": 4.330230288836846e-05,
      "loss": 1.9643,
      "step": 103000
    },
    {
      "epoch": 4.039812646370024,
      "grad_norm": 0.26670336723327637,
      "learning_rate": 4.3269841269841274e-05,
      "loss": 1.9649,
      "step": 103500
    },
    {
      "epoch": 4.059328649492584,
      "grad_norm": 0.2373337298631668,
      "learning_rate": 4.3237314597970334e-05,
      "loss": 1.9652,
      "step": 104000
    },
    {
      "epoch": 4.059328649492584,
      "eval_loss": 1.9568392038345337,
      "eval_runtime": 193.6291,
      "eval_samples_per_second": 38711.028,
      "eval_steps_per_second": 18.902,
      "step": 104000
    },
    {
      "epoch": 4.078844652615144,
      "grad_norm": 0.24649053812026978,
      "learning_rate": 4.32047879260994e-05,
      "loss": 1.9649,
      "step": 104500
    },
    {
      "epoch": 4.098360655737705,
      "grad_norm": 0.25354212522506714,
      "learning_rate": 4.317226125422847e-05,
      "loss": 1.965,
      "step": 105000
    },
    {
      "epoch": 4.117876658860266,
      "grad_norm": 0.24465230107307434,
      "learning_rate": 4.3139734582357536e-05,
      "loss": 1.9653,
      "step": 105500
    },
    {
      "epoch": 4.137392661982826,
      "grad_norm": 0.24341832101345062,
      "learning_rate": 4.3107272963830344e-05,
      "loss": 1.965,
      "step": 106000
    },
    {
      "epoch": 4.137392661982826,
      "eval_loss": 1.9564902782440186,
      "eval_runtime": 193.9149,
      "eval_samples_per_second": 38653.973,
      "eval_steps_per_second": 18.874,
      "step": 106000
    },
    {
      "epoch": 4.156908665105386,
      "grad_norm": 0.24162675440311432,
      "learning_rate": 4.307474629195941e-05,
      "loss": 1.9641,
      "step": 106500
    },
    {
      "epoch": 4.176424668227947,
      "grad_norm": 0.24346593022346497,
      "learning_rate": 4.304221962008848e-05,
      "loss": 1.9646,
      "step": 107000
    },
    {
      "epoch": 4.195940671350508,
      "grad_norm": 0.23513278365135193,
      "learning_rate": 4.300969294821754e-05,
      "loss": 1.9636,
      "step": 107500
    },
    {
      "epoch": 4.215456674473068,
      "grad_norm": 0.2444097250699997,
      "learning_rate": 4.2977166276346606e-05,
      "loss": 1.9644,
      "step": 108000
    },
    {
      "epoch": 4.215456674473068,
      "eval_loss": 1.9564728736877441,
      "eval_runtime": 193.4187,
      "eval_samples_per_second": 38753.154,
      "eval_steps_per_second": 18.923,
      "step": 108000
    },
    {
      "epoch": 4.2349726775956285,
      "grad_norm": 0.24950915575027466,
      "learning_rate": 4.2944704657819414e-05,
      "loss": 1.964,
      "step": 108500
    },
    {
      "epoch": 4.254488680718189,
      "grad_norm": 0.2622878849506378,
      "learning_rate": 4.291217798594848e-05,
      "loss": 1.9639,
      "step": 109000
    },
    {
      "epoch": 4.274004683840749,
      "grad_norm": 0.24169816076755524,
      "learning_rate": 4.287965131407755e-05,
      "loss": 1.9642,
      "step": 109500
    },
    {
      "epoch": 4.29352068696331,
      "grad_norm": 0.24681352078914642,
      "learning_rate": 4.284712464220661e-05,
      "loss": 1.9645,
      "step": 110000
    },
    {
      "epoch": 4.29352068696331,
      "eval_loss": 1.9557981491088867,
      "eval_runtime": 193.2404,
      "eval_samples_per_second": 38788.905,
      "eval_steps_per_second": 18.94,
      "step": 110000
    },
    {
      "epoch": 4.3130366900858705,
      "grad_norm": 0.2414121925830841,
      "learning_rate": 4.2814663023679417e-05,
      "loss": 1.9636,
      "step": 110500
    },
    {
      "epoch": 4.332552693208431,
      "grad_norm": 0.2535514235496521,
      "learning_rate": 4.2782136351808484e-05,
      "loss": 1.9636,
      "step": 111000
    },
    {
      "epoch": 4.352068696330991,
      "grad_norm": 0.243679478764534,
      "learning_rate": 4.274960967993755e-05,
      "loss": 1.9631,
      "step": 111500
    },
    {
      "epoch": 4.371584699453552,
      "grad_norm": 0.2503047287464142,
      "learning_rate": 4.271708300806662e-05,
      "loss": 1.9645,
      "step": 112000
    },
    {
      "epoch": 4.371584699453552,
      "eval_loss": 1.9556125402450562,
      "eval_runtime": 192.9092,
      "eval_samples_per_second": 38855.499,
      "eval_steps_per_second": 18.973,
      "step": 112000
    },
    {
      "epoch": 4.391100702576113,
      "grad_norm": 0.23772238194942474,
      "learning_rate": 4.2684621389539426e-05,
      "loss": 1.9633,
      "step": 112500
    },
    {
      "epoch": 4.410616705698673,
      "grad_norm": 0.24583393335342407,
      "learning_rate": 4.2652094717668487e-05,
      "loss": 1.9635,
      "step": 113000
    },
    {
      "epoch": 4.430132708821233,
      "grad_norm": 0.24433228373527527,
      "learning_rate": 4.261956804579756e-05,
      "loss": 1.9639,
      "step": 113500
    },
    {
      "epoch": 4.4496487119437935,
      "grad_norm": 0.24513787031173706,
      "learning_rate": 4.258704137392662e-05,
      "loss": 1.9626,
      "step": 114000
    },
    {
      "epoch": 4.4496487119437935,
      "eval_loss": 1.9555939435958862,
      "eval_runtime": 192.4766,
      "eval_samples_per_second": 38942.819,
      "eval_steps_per_second": 19.015,
      "step": 114000
    },
    {
      "epoch": 4.469164715066355,
      "grad_norm": 0.234394371509552,
      "learning_rate": 4.255457975539943e-05,
      "loss": 1.9634,
      "step": 114500
    },
    {
      "epoch": 4.488680718188915,
      "grad_norm": 0.24329747259616852,
      "learning_rate": 4.2522053083528496e-05,
      "loss": 1.9629,
      "step": 115000
    },
    {
      "epoch": 4.508196721311475,
      "grad_norm": 0.2416115254163742,
      "learning_rate": 4.2489526411657556e-05,
      "loss": 1.9636,
      "step": 115500
    },
    {
      "epoch": 4.527712724434036,
      "grad_norm": 0.2458135485649109,
      "learning_rate": 4.245699973978663e-05,
      "loss": 1.9625,
      "step": 116000
    },
    {
      "epoch": 4.527712724434036,
      "eval_loss": 1.9552594423294067,
      "eval_runtime": 193.7036,
      "eval_samples_per_second": 38696.146,
      "eval_steps_per_second": 18.895,
      "step": 116000
    },
    {
      "epoch": 4.547228727556597,
      "grad_norm": 0.24349211156368256,
      "learning_rate": 4.242447306791569e-05,
      "loss": 1.9635,
      "step": 116500
    },
    {
      "epoch": 4.566744730679157,
      "grad_norm": 0.23696382343769073,
      "learning_rate": 4.2392011449388506e-05,
      "loss": 1.9638,
      "step": 117000
    },
    {
      "epoch": 4.586260733801717,
      "grad_norm": 0.25891417264938354,
      "learning_rate": 4.2359484777517566e-05,
      "loss": 1.9633,
      "step": 117500
    },
    {
      "epoch": 4.605776736924278,
      "grad_norm": 0.23636826872825623,
      "learning_rate": 4.232695810564663e-05,
      "loss": 1.9631,
      "step": 118000
    },
    {
      "epoch": 4.605776736924278,
      "eval_loss": 1.9547327756881714,
      "eval_runtime": 193.2273,
      "eval_samples_per_second": 38791.532,
      "eval_steps_per_second": 18.941,
      "step": 118000
    },
    {
      "epoch": 4.625292740046838,
      "grad_norm": 0.23726679384708405,
      "learning_rate": 4.22944314337757e-05,
      "loss": 1.963,
      "step": 118500
    },
    {
      "epoch": 4.644808743169399,
      "grad_norm": 0.23904949426651,
      "learning_rate": 4.22619698152485e-05,
      "loss": 1.9634,
      "step": 119000
    },
    {
      "epoch": 4.6643247462919595,
      "grad_norm": 0.24166204035282135,
      "learning_rate": 4.2229443143377576e-05,
      "loss": 1.9627,
      "step": 119500
    },
    {
      "epoch": 4.68384074941452,
      "grad_norm": 0.24253682792186737,
      "learning_rate": 4.2196916471506636e-05,
      "loss": 1.963,
      "step": 120000
    },
    {
      "epoch": 4.68384074941452,
      "eval_loss": 1.9546278715133667,
      "eval_runtime": 193.7583,
      "eval_samples_per_second": 38685.213,
      "eval_steps_per_second": 18.89,
      "step": 120000
    },
    {
      "epoch": 4.70335675253708,
      "grad_norm": 0.23421324789524078,
      "learning_rate": 4.21643897996357e-05,
      "loss": 1.9633,
      "step": 120500
    },
    {
      "epoch": 4.722872755659641,
      "grad_norm": 0.2512665390968323,
      "learning_rate": 4.213192818110851e-05,
      "loss": 1.9633,
      "step": 121000
    },
    {
      "epoch": 4.742388758782202,
      "grad_norm": 0.24772460758686066,
      "learning_rate": 4.209940150923758e-05,
      "loss": 1.9626,
      "step": 121500
    },
    {
      "epoch": 4.761904761904762,
      "grad_norm": 0.2507304549217224,
      "learning_rate": 4.2066874837366645e-05,
      "loss": 1.9626,
      "step": 122000
    },
    {
      "epoch": 4.761904761904762,
      "eval_loss": 1.9544931650161743,
      "eval_runtime": 192.9378,
      "eval_samples_per_second": 38849.734,
      "eval_steps_per_second": 18.97,
      "step": 122000
    },
    {
      "epoch": 4.781420765027322,
      "grad_norm": 0.24143435060977936,
      "learning_rate": 4.2034348165495706e-05,
      "loss": 1.9626,
      "step": 122500
    },
    {
      "epoch": 4.800936768149883,
      "grad_norm": 0.23331129550933838,
      "learning_rate": 4.2001886546968514e-05,
      "loss": 1.9627,
      "step": 123000
    },
    {
      "epoch": 4.820452771272444,
      "grad_norm": 0.23629719018936157,
      "learning_rate": 4.196935987509758e-05,
      "loss": 1.9625,
      "step": 123500
    },
    {
      "epoch": 4.839968774395004,
      "grad_norm": 0.24692712724208832,
      "learning_rate": 4.193683320322665e-05,
      "loss": 1.9621,
      "step": 124000
    },
    {
      "epoch": 4.839968774395004,
      "eval_loss": 1.9542498588562012,
      "eval_runtime": 192.8075,
      "eval_samples_per_second": 38875.996,
      "eval_steps_per_second": 18.983,
      "step": 124000
    },
    {
      "epoch": 4.859484777517564,
      "grad_norm": 0.24408134818077087,
      "learning_rate": 4.1904306531355715e-05,
      "loss": 1.962,
      "step": 124500
    },
    {
      "epoch": 4.8790007806401245,
      "grad_norm": Infinity,
      "learning_rate": 4.187184491282852e-05,
      "loss": 1.9618,
      "step": 125000
    },
    {
      "epoch": 4.898516783762686,
      "grad_norm": 0.23156605660915375,
      "learning_rate": 4.1839318240957584e-05,
      "loss": 1.9624,
      "step": 125500
    },
    {
      "epoch": 4.918032786885246,
      "grad_norm": 0.23517468571662903,
      "learning_rate": 4.180679156908665e-05,
      "loss": 1.9619,
      "step": 126000
    },
    {
      "epoch": 4.918032786885246,
      "eval_loss": 1.9540314674377441,
      "eval_runtime": 192.7587,
      "eval_samples_per_second": 38885.839,
      "eval_steps_per_second": 18.987,
      "step": 126000
    },
    {
      "epoch": 4.937548790007806,
      "grad_norm": 0.23920728266239166,
      "learning_rate": 4.177426489721572e-05,
      "loss": 1.9617,
      "step": 126500
    },
    {
      "epoch": 4.957064793130367,
      "grad_norm": 0.2372412383556366,
      "learning_rate": 4.1741738225344785e-05,
      "loss": 1.9625,
      "step": 127000
    },
    {
      "epoch": 4.976580796252927,
      "grad_norm": 0.2417914718389511,
      "learning_rate": 4.170927660681759e-05,
      "loss": 1.9621,
      "step": 127500
    },
    {
      "epoch": 4.996096799375488,
      "grad_norm": 0.224818155169487,
      "learning_rate": 4.167674993494666e-05,
      "loss": 1.9612,
      "step": 128000
    },
    {
      "epoch": 4.996096799375488,
      "eval_loss": 1.953743577003479,
      "eval_runtime": 193.3377,
      "eval_samples_per_second": 38769.384,
      "eval_steps_per_second": 18.931,
      "step": 128000
    },
    {
      "epoch": 5.015612802498048,
      "grad_norm": 0.2408003956079483,
      "learning_rate": 4.164422326307573e-05,
      "loss": 1.962,
      "step": 128500
    },
    {
      "epoch": 5.035128805620609,
      "grad_norm": 0.23294934630393982,
      "learning_rate": 4.161169659120479e-05,
      "loss": 1.9615,
      "step": 129000
    },
    {
      "epoch": 5.054644808743169,
      "grad_norm": 0.2325880378484726,
      "learning_rate": 4.15792349726776e-05,
      "loss": 1.9617,
      "step": 129500
    },
    {
      "epoch": 5.07416081186573,
      "grad_norm": 0.26442649960517883,
      "learning_rate": 4.154670830080666e-05,
      "loss": 1.9619,
      "step": 130000
    },
    {
      "epoch": 5.07416081186573,
      "eval_loss": 1.9534510374069214,
      "eval_runtime": 193.1191,
      "eval_samples_per_second": 38813.271,
      "eval_steps_per_second": 18.952,
      "step": 130000
    },
    {
      "epoch": 5.0936768149882905,
      "grad_norm": 0.2500784695148468,
      "learning_rate": 4.151418162893573e-05,
      "loss": 1.9608,
      "step": 130500
    },
    {
      "epoch": 5.113192818110851,
      "grad_norm": 0.2411646842956543,
      "learning_rate": 4.14816549570648e-05,
      "loss": 1.9611,
      "step": 131000
    },
    {
      "epoch": 5.132708821233411,
      "grad_norm": 0.24282725155353546,
      "learning_rate": 4.14491933385376e-05,
      "loss": 1.9617,
      "step": 131500
    },
    {
      "epoch": 5.152224824355972,
      "grad_norm": 0.2250215858221054,
      "learning_rate": 4.141666666666667e-05,
      "loss": 1.9617,
      "step": 132000
    },
    {
      "epoch": 5.152224824355972,
      "eval_loss": 1.953151822090149,
      "eval_runtime": 192.9874,
      "eval_samples_per_second": 38839.752,
      "eval_steps_per_second": 18.965,
      "step": 132000
    },
    {
      "epoch": 5.171740827478533,
      "grad_norm": 0.2306421548128128,
      "learning_rate": 4.138413999479573e-05,
      "loss": 1.9612,
      "step": 132500
    },
    {
      "epoch": 5.191256830601093,
      "grad_norm": 0.22832538187503815,
      "learning_rate": 4.13516133229248e-05,
      "loss": 1.961,
      "step": 133000
    },
    {
      "epoch": 5.210772833723653,
      "grad_norm": 0.2415931075811386,
      "learning_rate": 4.131915170439761e-05,
      "loss": 1.9609,
      "step": 133500
    },
    {
      "epoch": 5.2302888368462135,
      "grad_norm": 0.23558808863162994,
      "learning_rate": 4.128662503252667e-05,
      "loss": 1.9614,
      "step": 134000
    },
    {
      "epoch": 5.2302888368462135,
      "eval_loss": 1.9532160758972168,
      "eval_runtime": 193.0214,
      "eval_samples_per_second": 38832.906,
      "eval_steps_per_second": 18.962,
      "step": 134000
    },
    {
      "epoch": 5.249804839968775,
      "grad_norm": 0.23949818313121796,
      "learning_rate": 4.125409836065574e-05,
      "loss": 1.9611,
      "step": 134500
    },
    {
      "epoch": 5.269320843091335,
      "grad_norm": 0.24984212219715118,
      "learning_rate": 4.12215716887848e-05,
      "loss": 1.9608,
      "step": 135000
    },
    {
      "epoch": 5.288836846213895,
      "grad_norm": 0.23794132471084595,
      "learning_rate": 4.118911007025761e-05,
      "loss": 1.9599,
      "step": 135500
    },
    {
      "epoch": 5.308352849336456,
      "grad_norm": 0.23172445595264435,
      "learning_rate": 4.115658339838668e-05,
      "loss": 1.9606,
      "step": 136000
    },
    {
      "epoch": 5.308352849336456,
      "eval_loss": 1.9531170129776,
      "eval_runtime": 192.6066,
      "eval_samples_per_second": 38916.553,
      "eval_steps_per_second": 19.002,
      "step": 136000
    },
    {
      "epoch": 5.327868852459017,
      "grad_norm": 0.2320716679096222,
      "learning_rate": 4.1124056726515745e-05,
      "loss": 1.9612,
      "step": 136500
    },
    {
      "epoch": 5.347384855581577,
      "grad_norm": 0.2260817438364029,
      "learning_rate": 4.109153005464481e-05,
      "loss": 1.9603,
      "step": 137000
    },
    {
      "epoch": 5.366900858704137,
      "grad_norm": 0.23860186338424683,
      "learning_rate": 4.105900338277387e-05,
      "loss": 1.9605,
      "step": 137500
    },
    {
      "epoch": 5.386416861826698,
      "grad_norm": 0.24193550646305084,
      "learning_rate": 4.102654176424668e-05,
      "loss": 1.9601,
      "step": 138000
    },
    {
      "epoch": 5.386416861826698,
      "eval_loss": 1.9525487422943115,
      "eval_runtime": 192.8203,
      "eval_samples_per_second": 38873.413,
      "eval_steps_per_second": 18.981,
      "step": 138000
    },
    {
      "epoch": 5.405932864949259,
      "grad_norm": 0.23064878582954407,
      "learning_rate": 4.099401509237575e-05,
      "loss": 1.9606,
      "step": 138500
    },
    {
      "epoch": 5.425448868071819,
      "grad_norm": 0.23567865788936615,
      "learning_rate": 4.0961488420504815e-05,
      "loss": 1.9605,
      "step": 139000
    },
    {
      "epoch": 5.444964871194379,
      "grad_norm": 0.2248997539281845,
      "learning_rate": 4.092896174863388e-05,
      "loss": 1.9608,
      "step": 139500
    },
    {
      "epoch": 5.46448087431694,
      "grad_norm": 0.24235576391220093,
      "learning_rate": 4.089650013010669e-05,
      "loss": 1.9606,
      "step": 140000
    },
    {
      "epoch": 5.46448087431694,
      "eval_loss": 1.9525341987609863,
      "eval_runtime": 192.2966,
      "eval_samples_per_second": 38979.275,
      "eval_steps_per_second": 19.033,
      "step": 140000
    },
    {
      "epoch": 5.4839968774395,
      "grad_norm": 0.23753389716148376,
      "learning_rate": 4.086397345823576e-05,
      "loss": 1.9597,
      "step": 140500
    },
    {
      "epoch": 5.503512880562061,
      "grad_norm": 0.23917488753795624,
      "learning_rate": 4.083144678636482e-05,
      "loss": 1.9608,
      "step": 141000
    },
    {
      "epoch": 5.5230288836846215,
      "grad_norm": 0.22614352405071259,
      "learning_rate": 4.0798920114493885e-05,
      "loss": 1.9605,
      "step": 141500
    },
    {
      "epoch": 5.542544886807182,
      "grad_norm": 0.2357402741909027,
      "learning_rate": 4.07664584959667e-05,
      "loss": 1.9606,
      "step": 142000
    },
    {
      "epoch": 5.542544886807182,
      "eval_loss": 1.9523028135299683,
      "eval_runtime": 191.7044,
      "eval_samples_per_second": 39099.683,
      "eval_steps_per_second": 19.092,
      "step": 142000
    },
    {
      "epoch": 5.562060889929742,
      "grad_norm": 0.24488465487957,
      "learning_rate": 4.073393182409576e-05,
      "loss": 1.9603,
      "step": 142500
    },
    {
      "epoch": 5.581576893052302,
      "grad_norm": 0.24236683547496796,
      "learning_rate": 4.070140515222483e-05,
      "loss": 1.96,
      "step": 143000
    },
    {
      "epoch": 5.601092896174864,
      "grad_norm": 0.23586028814315796,
      "learning_rate": 4.0668878480353895e-05,
      "loss": 1.9599,
      "step": 143500
    },
    {
      "epoch": 5.620608899297424,
      "grad_norm": 0.25049450993537903,
      "learning_rate": 4.0636416861826696e-05,
      "loss": 1.9606,
      "step": 144000
    },
    {
      "epoch": 5.620608899297424,
      "eval_loss": 1.9521067142486572,
      "eval_runtime": 192.0509,
      "eval_samples_per_second": 39029.154,
      "eval_steps_per_second": 19.057,
      "step": 144000
    },
    {
      "epoch": 5.640124902419984,
      "grad_norm": 0.23996059596538544,
      "learning_rate": 4.060389018995577e-05,
      "loss": 1.9601,
      "step": 144500
    },
    {
      "epoch": 5.6596409055425445,
      "grad_norm": 0.23598632216453552,
      "learning_rate": 4.057136351808483e-05,
      "loss": 1.9597,
      "step": 145000
    },
    {
      "epoch": 5.679156908665106,
      "grad_norm": 0.24640433490276337,
      "learning_rate": 4.05388368462139e-05,
      "loss": 1.9597,
      "step": 145500
    },
    {
      "epoch": 5.698672911787666,
      "grad_norm": 0.23412802815437317,
      "learning_rate": 4.0506375227686706e-05,
      "loss": 1.9596,
      "step": 146000
    },
    {
      "epoch": 5.698672911787666,
      "eval_loss": 1.9518413543701172,
      "eval_runtime": 192.2872,
      "eval_samples_per_second": 38981.191,
      "eval_steps_per_second": 19.034,
      "step": 146000
    },
    {
      "epoch": 5.718188914910226,
      "grad_norm": 0.22518688440322876,
      "learning_rate": 4.0473848555815766e-05,
      "loss": 1.9594,
      "step": 146500
    },
    {
      "epoch": 5.737704918032787,
      "grad_norm": 0.22855880856513977,
      "learning_rate": 4.044132188394484e-05,
      "loss": 1.9598,
      "step": 147000
    },
    {
      "epoch": 5.757220921155348,
      "grad_norm": 0.2373548299074173,
      "learning_rate": 4.04087952120739e-05,
      "loss": 1.9598,
      "step": 147500
    },
    {
      "epoch": 5.776736924277908,
      "grad_norm": 0.24908684194087982,
      "learning_rate": 4.037633359354671e-05,
      "loss": 1.9594,
      "step": 148000
    },
    {
      "epoch": 5.776736924277908,
      "eval_loss": 1.951762080192566,
      "eval_runtime": 192.134,
      "eval_samples_per_second": 39012.264,
      "eval_steps_per_second": 19.049,
      "step": 148000
    },
    {
      "epoch": 5.796252927400468,
      "grad_norm": 0.23038029670715332,
      "learning_rate": 4.0343806921675775e-05,
      "loss": 1.9601,
      "step": 148500
    },
    {
      "epoch": 5.815768930523029,
      "grad_norm": 0.23773197829723358,
      "learning_rate": 4.0311280249804836e-05,
      "loss": 1.9598,
      "step": 149000
    },
    {
      "epoch": 5.835284933645589,
      "grad_norm": 0.2391309142112732,
      "learning_rate": 4.027875357793391e-05,
      "loss": 1.9591,
      "step": 149500
    },
    {
      "epoch": 5.85480093676815,
      "grad_norm": 0.2322806864976883,
      "learning_rate": 4.024629195940672e-05,
      "loss": 1.9598,
      "step": 150000
    },
    {
      "epoch": 5.85480093676815,
      "eval_loss": 1.951489806175232,
      "eval_runtime": 192.6863,
      "eval_samples_per_second": 38900.438,
      "eval_steps_per_second": 18.995,
      "step": 150000
    },
    {
      "epoch": 5.8743169398907105,
      "grad_norm": 0.22115035355091095,
      "learning_rate": 4.0213765287535785e-05,
      "loss": 1.9592,
      "step": 150500
    },
    {
      "epoch": 5.893832943013271,
      "grad_norm": 0.25063666701316833,
      "learning_rate": 4.0181238615664845e-05,
      "loss": 1.96,
      "step": 151000
    },
    {
      "epoch": 5.913348946135831,
      "grad_norm": 0.2617420554161072,
      "learning_rate": 4.014871194379391e-05,
      "loss": 1.9595,
      "step": 151500
    },
    {
      "epoch": 5.932864949258392,
      "grad_norm": 0.23092837631702423,
      "learning_rate": 4.011625032526672e-05,
      "loss": 1.96,
      "step": 152000
    },
    {
      "epoch": 5.932864949258392,
      "eval_loss": 1.9511582851409912,
      "eval_runtime": 193.3479,
      "eval_samples_per_second": 38767.331,
      "eval_steps_per_second": 18.93,
      "step": 152000
    },
    {
      "epoch": 5.9523809523809526,
      "grad_norm": 0.2350328415632248,
      "learning_rate": 4.008372365339579e-05,
      "loss": 1.9598,
      "step": 152500
    },
    {
      "epoch": 5.971896955503513,
      "grad_norm": 0.23514102399349213,
      "learning_rate": 4.0051196981524855e-05,
      "loss": 1.9593,
      "step": 153000
    },
    {
      "epoch": 5.991412958626073,
      "grad_norm": 0.2417343258857727,
      "learning_rate": 4.0018670309653915e-05,
      "loss": 1.9598,
      "step": 153500
    },
    {
      "epoch": 6.0109289617486334,
      "grad_norm": 0.24493514001369476,
      "learning_rate": 3.998620869112672e-05,
      "loss": 1.9593,
      "step": 154000
    },
    {
      "epoch": 6.0109289617486334,
      "eval_loss": 1.9512300491333008,
      "eval_runtime": 192.9978,
      "eval_samples_per_second": 38837.664,
      "eval_steps_per_second": 18.964,
      "step": 154000
    },
    {
      "epoch": 6.030444964871195,
      "grad_norm": 0.22710469365119934,
      "learning_rate": 3.995368201925579e-05,
      "loss": 1.959,
      "step": 154500
    },
    {
      "epoch": 6.049960967993755,
      "grad_norm": 0.23866020143032074,
      "learning_rate": 3.992115534738486e-05,
      "loss": 1.9586,
      "step": 155000
    },
    {
      "epoch": 6.069476971116315,
      "grad_norm": 0.23382283747196198,
      "learning_rate": 3.9888628675513925e-05,
      "loss": 1.9585,
      "step": 155500
    },
    {
      "epoch": 6.0889929742388755,
      "grad_norm": 0.22804301977157593,
      "learning_rate": 3.985616705698673e-05,
      "loss": 1.9584,
      "step": 156000
    },
    {
      "epoch": 6.0889929742388755,
      "eval_loss": 1.9510594606399536,
      "eval_runtime": 192.8473,
      "eval_samples_per_second": 38867.979,
      "eval_steps_per_second": 18.979,
      "step": 156000
    },
    {
      "epoch": 6.108508977361437,
      "grad_norm": 0.24709579348564148,
      "learning_rate": 3.982364038511579e-05,
      "loss": 1.9579,
      "step": 156500
    },
    {
      "epoch": 6.128024980483997,
      "grad_norm": 0.23920705914497375,
      "learning_rate": 3.979111371324487e-05,
      "loss": 1.9591,
      "step": 157000
    },
    {
      "epoch": 6.147540983606557,
      "grad_norm": 0.23277905583381653,
      "learning_rate": 3.975858704137393e-05,
      "loss": 1.9588,
      "step": 157500
    },
    {
      "epoch": 6.167056986729118,
      "grad_norm": 0.23742438852787018,
      "learning_rate": 3.9726125422846736e-05,
      "loss": 1.9583,
      "step": 158000
    },
    {
      "epoch": 6.167056986729118,
      "eval_loss": 1.9508284330368042,
      "eval_runtime": 190.5942,
      "eval_samples_per_second": 39327.443,
      "eval_steps_per_second": 19.203,
      "step": 158000
    },
    {
      "epoch": 6.186572989851679,
      "grad_norm": 0.24219785630702972,
      "learning_rate": 3.96935987509758e-05,
      "loss": 1.9593,
      "step": 158500
    },
    {
      "epoch": 6.206088992974239,
      "grad_norm": 0.2313907891511917,
      "learning_rate": 3.966107207910486e-05,
      "loss": 1.9589,
      "step": 159000
    },
    {
      "epoch": 6.225604996096799,
      "grad_norm": 0.23031191527843475,
      "learning_rate": 3.962854540723394e-05,
      "loss": 1.9588,
      "step": 159500
    },
    {
      "epoch": 6.24512099921936,
      "grad_norm": 0.24557848274707794,
      "learning_rate": 3.959608378870674e-05,
      "loss": 1.9583,
      "step": 160000
    },
    {
      "epoch": 6.24512099921936,
      "eval_loss": 1.9506819248199463,
      "eval_runtime": 190.3124,
      "eval_samples_per_second": 39385.671,
      "eval_steps_per_second": 19.232,
      "step": 160000
    },
    {
      "epoch": 6.26463700234192,
      "grad_norm": 0.22190196812152863,
      "learning_rate": 3.9563557116835806e-05,
      "loss": 1.9585,
      "step": 160500
    },
    {
      "epoch": 6.284153005464481,
      "grad_norm": 0.2357165664434433,
      "learning_rate": 3.953103044496487e-05,
      "loss": 1.9586,
      "step": 161000
    },
    {
      "epoch": 6.3036690085870415,
      "grad_norm": 0.23731790482997894,
      "learning_rate": 3.949850377309394e-05,
      "loss": 1.959,
      "step": 161500
    },
    {
      "epoch": 6.323185011709602,
      "grad_norm": 0.228749081492424,
      "learning_rate": 3.946604215456675e-05,
      "loss": 1.958,
      "step": 162000
    },
    {
      "epoch": 6.323185011709602,
      "eval_loss": 1.9504683017730713,
      "eval_runtime": 190.5837,
      "eval_samples_per_second": 39329.616,
      "eval_steps_per_second": 19.204,
      "step": 162000
    },
    {
      "epoch": 6.342701014832162,
      "grad_norm": 0.23273321986198425,
      "learning_rate": 3.943351548269581e-05,
      "loss": 1.9581,
      "step": 162500
    },
    {
      "epoch": 6.362217017954723,
      "grad_norm": 0.2438354194164276,
      "learning_rate": 3.940098881082488e-05,
      "loss": 1.9575,
      "step": 163000
    },
    {
      "epoch": 6.381733021077284,
      "grad_norm": 0.24943578243255615,
      "learning_rate": 3.936846213895394e-05,
      "loss": 1.9579,
      "step": 163500
    },
    {
      "epoch": 6.401249024199844,
      "grad_norm": 0.22290226817131042,
      "learning_rate": 3.933600052042675e-05,
      "loss": 1.9583,
      "step": 164000
    },
    {
      "epoch": 6.401249024199844,
      "eval_loss": 1.9505351781845093,
      "eval_runtime": 190.5679,
      "eval_samples_per_second": 39332.865,
      "eval_steps_per_second": 19.206,
      "step": 164000
    },
    {
      "epoch": 6.420765027322404,
      "grad_norm": 0.24243532121181488,
      "learning_rate": 3.930347384855582e-05,
      "loss": 1.9585,
      "step": 164500
    },
    {
      "epoch": 6.4402810304449645,
      "grad_norm": 0.2549643814563751,
      "learning_rate": 3.9270947176684885e-05,
      "loss": 1.9579,
      "step": 165000
    },
    {
      "epoch": 6.459797033567526,
      "grad_norm": 0.2250378578901291,
      "learning_rate": 3.923842050481395e-05,
      "loss": 1.9583,
      "step": 165500
    },
    {
      "epoch": 6.479313036690086,
      "grad_norm": 0.22950410842895508,
      "learning_rate": 3.920595888628676e-05,
      "loss": 1.9579,
      "step": 166000
    },
    {
      "epoch": 6.479313036690086,
      "eval_loss": 1.9503371715545654,
      "eval_runtime": 192.5459,
      "eval_samples_per_second": 38928.814,
      "eval_steps_per_second": 19.008,
      "step": 166000
    },
    {
      "epoch": 6.498829039812646,
      "grad_norm": 0.2209376096725464,
      "learning_rate": 3.917343221441582e-05,
      "loss": 1.958,
      "step": 166500
    },
    {
      "epoch": 6.518345042935207,
      "grad_norm": 0.24552462995052338,
      "learning_rate": 3.914090554254489e-05,
      "loss": 1.9582,
      "step": 167000
    },
    {
      "epoch": 6.537861046057768,
      "grad_norm": 0.26568692922592163,
      "learning_rate": 3.9108378870673955e-05,
      "loss": 1.9571,
      "step": 167500
    },
    {
      "epoch": 6.557377049180328,
      "grad_norm": 0.22841668128967285,
      "learning_rate": 3.907591725214676e-05,
      "loss": 1.9587,
      "step": 168000
    },
    {
      "epoch": 6.557377049180328,
      "eval_loss": 1.9500914812088013,
      "eval_runtime": 192.9,
      "eval_samples_per_second": 38857.356,
      "eval_steps_per_second": 18.974,
      "step": 168000
    },
    {
      "epoch": 6.576893052302888,
      "grad_norm": 0.24764467775821686,
      "learning_rate": 3.904339058027583e-05,
      "loss": 1.9577,
      "step": 168500
    },
    {
      "epoch": 6.596409055425449,
      "grad_norm": 0.2623327672481537,
      "learning_rate": 3.901086390840489e-05,
      "loss": 1.9575,
      "step": 169000
    },
    {
      "epoch": 6.61592505854801,
      "grad_norm": 0.22657106816768646,
      "learning_rate": 3.8978402289877705e-05,
      "loss": 1.9584,
      "step": 169500
    },
    {
      "epoch": 6.63544106167057,
      "grad_norm": 0.2274225950241089,
      "learning_rate": 3.8945875618006766e-05,
      "loss": 1.9584,
      "step": 170000
    },
    {
      "epoch": 6.63544106167057,
      "eval_loss": 1.949777603149414,
      "eval_runtime": 192.7227,
      "eval_samples_per_second": 38893.109,
      "eval_steps_per_second": 18.991,
      "step": 170000
    },
    {
      "epoch": 6.65495706479313,
      "grad_norm": 0.23036377131938934,
      "learning_rate": 3.891334894613583e-05,
      "loss": 1.9584,
      "step": 170500
    },
    {
      "epoch": 6.674473067915691,
      "grad_norm": 0.22331960499286652,
      "learning_rate": 3.88808222742649e-05,
      "loss": 1.9582,
      "step": 171000
    },
    {
      "epoch": 6.693989071038251,
      "grad_norm": 0.23748204112052917,
      "learning_rate": 3.884829560239396e-05,
      "loss": 1.9578,
      "step": 171500
    },
    {
      "epoch": 6.713505074160812,
      "grad_norm": 0.24303199350833893,
      "learning_rate": 3.8815768930523034e-05,
      "loss": 1.9576,
      "step": 172000
    },
    {
      "epoch": 6.713505074160812,
      "eval_loss": 1.9496687650680542,
      "eval_runtime": 190.3441,
      "eval_samples_per_second": 39379.127,
      "eval_steps_per_second": 19.228,
      "step": 172000
    },
    {
      "epoch": 6.7330210772833725,
      "grad_norm": 0.24477466940879822,
      "learning_rate": 3.8783242258652095e-05,
      "loss": 1.957,
      "step": 172500
    },
    {
      "epoch": 6.752537080405933,
      "grad_norm": 0.23055818676948547,
      "learning_rate": 3.875071558678116e-05,
      "loss": 1.9574,
      "step": 173000
    },
    {
      "epoch": 6.772053083528493,
      "grad_norm": 0.22582434117794037,
      "learning_rate": 3.871825396825397e-05,
      "loss": 1.9572,
      "step": 173500
    },
    {
      "epoch": 6.791569086651053,
      "grad_norm": 0.23240624368190765,
      "learning_rate": 3.868572729638304e-05,
      "loss": 1.9582,
      "step": 174000
    },
    {
      "epoch": 6.791569086651053,
      "eval_loss": 1.9495441913604736,
      "eval_runtime": 190.5586,
      "eval_samples_per_second": 39334.782,
      "eval_steps_per_second": 19.207,
      "step": 174000
    },
    {
      "epoch": 6.811085089773615,
      "grad_norm": 0.23398762941360474,
      "learning_rate": 3.8653200624512104e-05,
      "loss": 1.9573,
      "step": 174500
    },
    {
      "epoch": 6.830601092896175,
      "grad_norm": 0.23647360503673553,
      "learning_rate": 3.8620673952641165e-05,
      "loss": 1.958,
      "step": 175000
    },
    {
      "epoch": 6.850117096018735,
      "grad_norm": 0.23409441113471985,
      "learning_rate": 3.858821233411398e-05,
      "loss": 1.957,
      "step": 175500
    },
    {
      "epoch": 6.8696330991412955,
      "grad_norm": 0.23844777047634125,
      "learning_rate": 3.855568566224304e-05,
      "loss": 1.9575,
      "step": 176000
    },
    {
      "epoch": 6.8696330991412955,
      "eval_loss": 1.9494385719299316,
      "eval_runtime": 191.2868,
      "eval_samples_per_second": 39185.045,
      "eval_steps_per_second": 19.134,
      "step": 176000
    },
    {
      "epoch": 6.889149102263857,
      "grad_norm": 0.2282276153564453,
      "learning_rate": 3.852315899037211e-05,
      "loss": 1.9579,
      "step": 176500
    },
    {
      "epoch": 6.908665105386417,
      "grad_norm": 0.2219032347202301,
      "learning_rate": 3.8490632318501174e-05,
      "loss": 1.958,
      "step": 177000
    },
    {
      "epoch": 6.928181108508977,
      "grad_norm": 0.2284412831068039,
      "learning_rate": 3.845817069997398e-05,
      "loss": 1.9569,
      "step": 177500
    },
    {
      "epoch": 6.947697111631538,
      "grad_norm": 0.23489391803741455,
      "learning_rate": 3.842564402810305e-05,
      "loss": 1.957,
      "step": 178000
    },
    {
      "epoch": 6.947697111631538,
      "eval_loss": 1.9493666887283325,
      "eval_runtime": 193.1447,
      "eval_samples_per_second": 38808.121,
      "eval_steps_per_second": 18.95,
      "step": 178000
    },
    {
      "epoch": 6.967213114754099,
      "grad_norm": 0.22593863308429718,
      "learning_rate": 3.839311735623211e-05,
      "loss": 1.9572,
      "step": 178500
    },
    {
      "epoch": 6.986729117876659,
      "grad_norm": 0.23208937048912048,
      "learning_rate": 3.8360590684361184e-05,
      "loss": 1.9581,
      "step": 179000
    },
    {
      "epoch": 7.006245120999219,
      "grad_norm": 0.2507576048374176,
      "learning_rate": 3.8328129065833985e-05,
      "loss": 1.9565,
      "step": 179500
    },
    {
      "epoch": 7.02576112412178,
      "grad_norm": 0.23214058578014374,
      "learning_rate": 3.829560239396305e-05,
      "loss": 1.9575,
      "step": 180000
    },
    {
      "epoch": 7.02576112412178,
      "eval_loss": 1.9489688873291016,
      "eval_runtime": 192.9929,
      "eval_samples_per_second": 38838.65,
      "eval_steps_per_second": 18.964,
      "step": 180000
    },
    {
      "epoch": 7.04527712724434,
      "grad_norm": 0.2277052253484726,
      "learning_rate": 3.826307572209212e-05,
      "loss": 1.9568,
      "step": 180500
    },
    {
      "epoch": 7.064793130366901,
      "grad_norm": 0.23993371427059174,
      "learning_rate": 3.823054905022118e-05,
      "loss": 1.9564,
      "step": 181000
    },
    {
      "epoch": 7.0843091334894615,
      "grad_norm": 0.2413729727268219,
      "learning_rate": 3.819808743169399e-05,
      "loss": 1.9568,
      "step": 181500
    },
    {
      "epoch": 7.103825136612022,
      "grad_norm": 0.2263757586479187,
      "learning_rate": 3.8165560759823055e-05,
      "loss": 1.9565,
      "step": 182000
    },
    {
      "epoch": 7.103825136612022,
      "eval_loss": 1.9492725133895874,
      "eval_runtime": 190.5785,
      "eval_samples_per_second": 39330.694,
      "eval_steps_per_second": 19.205,
      "step": 182000
    },
    {
      "epoch": 7.123341139734582,
      "grad_norm": 0.23711581528186798,
      "learning_rate": 3.813303408795212e-05,
      "loss": 1.9569,
      "step": 182500
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 0.2418554723262787,
      "learning_rate": 3.810050741608119e-05,
      "loss": 1.9566,
      "step": 183000
    },
    {
      "epoch": 7.1623731459797035,
      "grad_norm": 0.2351323515176773,
      "learning_rate": 3.8068045797554e-05,
      "loss": 1.9567,
      "step": 183500
    },
    {
      "epoch": 7.181889149102264,
      "grad_norm": 0.24321986734867096,
      "learning_rate": 3.8035519125683064e-05,
      "loss": 1.9568,
      "step": 184000
    },
    {
      "epoch": 7.181889149102264,
      "eval_loss": 1.948976993560791,
      "eval_runtime": 190.3262,
      "eval_samples_per_second": 39382.819,
      "eval_steps_per_second": 19.23,
      "step": 184000
    },
    {
      "epoch": 7.201405152224824,
      "grad_norm": 0.2222474068403244,
      "learning_rate": 3.8002992453812125e-05,
      "loss": 1.9563,
      "step": 184500
    },
    {
      "epoch": 7.220921155347384,
      "grad_norm": 0.2326420396566391,
      "learning_rate": 3.797046578194119e-05,
      "loss": 1.9555,
      "step": 185000
    },
    {
      "epoch": 7.240437158469946,
      "grad_norm": 0.2246939241886139,
      "learning_rate": 3.793800416341401e-05,
      "loss": 1.9566,
      "step": 185500
    },
    {
      "epoch": 7.259953161592506,
      "grad_norm": 0.23470333218574524,
      "learning_rate": 3.790547749154307e-05,
      "loss": 1.9563,
      "step": 186000
    },
    {
      "epoch": 7.259953161592506,
      "eval_loss": 1.9487829208374023,
      "eval_runtime": 192.762,
      "eval_samples_per_second": 38885.175,
      "eval_steps_per_second": 18.987,
      "step": 186000
    },
    {
      "epoch": 7.279469164715066,
      "grad_norm": 0.22148238122463226,
      "learning_rate": 3.7872950819672134e-05,
      "loss": 1.9565,
      "step": 186500
    },
    {
      "epoch": 7.2989851678376265,
      "grad_norm": 0.2317401021718979,
      "learning_rate": 3.78404241478012e-05,
      "loss": 1.956,
      "step": 187000
    },
    {
      "epoch": 7.318501170960188,
      "grad_norm": 0.2360248863697052,
      "learning_rate": 3.7807962529274e-05,
      "loss": 1.957,
      "step": 187500
    },
    {
      "epoch": 7.338017174082748,
      "grad_norm": 0.22197505831718445,
      "learning_rate": 3.777543585740308e-05,
      "loss": 1.9559,
      "step": 188000
    },
    {
      "epoch": 7.338017174082748,
      "eval_loss": 1.948575496673584,
      "eval_runtime": 192.0137,
      "eval_samples_per_second": 39036.7,
      "eval_steps_per_second": 19.061,
      "step": 188000
    },
    {
      "epoch": 7.357533177205308,
      "grad_norm": 0.22836466133594513,
      "learning_rate": 3.774290918553214e-05,
      "loss": 1.9567,
      "step": 188500
    },
    {
      "epoch": 7.377049180327869,
      "grad_norm": 0.21525733172893524,
      "learning_rate": 3.7710382513661204e-05,
      "loss": 1.9564,
      "step": 189000
    },
    {
      "epoch": 7.396565183450429,
      "grad_norm": 0.2350900024175644,
      "learning_rate": 3.767785584179027e-05,
      "loss": 1.9561,
      "step": 189500
    },
    {
      "epoch": 7.41608118657299,
      "grad_norm": 0.24108874797821045,
      "learning_rate": 3.764539422326307e-05,
      "loss": 1.9564,
      "step": 190000
    },
    {
      "epoch": 7.41608118657299,
      "eval_loss": 1.9484848976135254,
      "eval_runtime": 190.0415,
      "eval_samples_per_second": 39441.819,
      "eval_steps_per_second": 19.259,
      "step": 190000
    },
    {
      "epoch": 7.43559718969555,
      "grad_norm": 0.23786067962646484,
      "learning_rate": 3.761286755139215e-05,
      "loss": 1.9566,
      "step": 190500
    },
    {
      "epoch": 7.455113192818111,
      "grad_norm": 0.23138022422790527,
      "learning_rate": 3.758034087952121e-05,
      "loss": 1.9565,
      "step": 191000
    },
    {
      "epoch": 7.474629195940671,
      "grad_norm": 0.23444651067256927,
      "learning_rate": 3.7547814207650274e-05,
      "loss": 1.9559,
      "step": 191500
    },
    {
      "epoch": 7.494145199063232,
      "grad_norm": 0.22086846828460693,
      "learning_rate": 3.751535258912308e-05,
      "loss": 1.9561,
      "step": 192000
    },
    {
      "epoch": 7.494145199063232,
      "eval_loss": 1.9483526945114136,
      "eval_runtime": 191.2331,
      "eval_samples_per_second": 39196.051,
      "eval_steps_per_second": 19.139,
      "step": 192000
    },
    {
      "epoch": 7.5136612021857925,
      "grad_norm": 0.24222418665885925,
      "learning_rate": 3.748282591725215e-05,
      "loss": 1.9562,
      "step": 192500
    },
    {
      "epoch": 7.533177205308353,
      "grad_norm": 0.23717963695526123,
      "learning_rate": 3.7450299245381217e-05,
      "loss": 1.9565,
      "step": 193000
    },
    {
      "epoch": 7.552693208430913,
      "grad_norm": 0.24650819599628448,
      "learning_rate": 3.741777257351028e-05,
      "loss": 1.9562,
      "step": 193500
    },
    {
      "epoch": 7.572209211553474,
      "grad_norm": 0.234359011054039,
      "learning_rate": 3.7385310954983085e-05,
      "loss": 1.9557,
      "step": 194000
    },
    {
      "epoch": 7.572209211553474,
      "eval_loss": 1.9482589960098267,
      "eval_runtime": 192.8844,
      "eval_samples_per_second": 38860.486,
      "eval_steps_per_second": 18.975,
      "step": 194000
    },
    {
      "epoch": 7.591725214676035,
      "grad_norm": 0.2288089394569397,
      "learning_rate": 3.735278428311215e-05,
      "loss": 1.9559,
      "step": 194500
    },
    {
      "epoch": 7.611241217798595,
      "grad_norm": 0.25187161564826965,
      "learning_rate": 3.732025761124122e-05,
      "loss": 1.9566,
      "step": 195000
    },
    {
      "epoch": 7.630757220921155,
      "grad_norm": 0.24110563099384308,
      "learning_rate": 3.7287730939370287e-05,
      "loss": 1.9552,
      "step": 195500
    },
    {
      "epoch": 7.6502732240437155,
      "grad_norm": 0.22848033905029297,
      "learning_rate": 3.7255269320843094e-05,
      "loss": 1.9561,
      "step": 196000
    },
    {
      "epoch": 7.6502732240437155,
      "eval_loss": 1.948004126548767,
      "eval_runtime": 192.1248,
      "eval_samples_per_second": 39014.137,
      "eval_steps_per_second": 19.05,
      "step": 196000
    },
    {
      "epoch": 7.669789227166277,
      "grad_norm": 0.22810354828834534,
      "learning_rate": 3.722274264897216e-05,
      "loss": 1.9556,
      "step": 196500
    },
    {
      "epoch": 7.689305230288837,
      "grad_norm": 0.2222909778356552,
      "learning_rate": 3.719021597710122e-05,
      "loss": 1.956,
      "step": 197000
    },
    {
      "epoch": 7.708821233411397,
      "grad_norm": 0.2329235076904297,
      "learning_rate": 3.715768930523029e-05,
      "loss": 1.9555,
      "step": 197500
    },
    {
      "epoch": 7.7283372365339575,
      "grad_norm": 0.23613151907920837,
      "learning_rate": 3.71252276867031e-05,
      "loss": 1.9561,
      "step": 198000
    },
    {
      "epoch": 7.7283372365339575,
      "eval_loss": 1.947933554649353,
      "eval_runtime": 190.4804,
      "eval_samples_per_second": 39350.938,
      "eval_steps_per_second": 19.215,
      "step": 198000
    },
    {
      "epoch": 7.747853239656519,
      "grad_norm": 0.23680990934371948,
      "learning_rate": 3.7092701014832164e-05,
      "loss": 1.9562,
      "step": 198500
    },
    {
      "epoch": 7.767369242779079,
      "grad_norm": 0.24794678390026093,
      "learning_rate": 3.706017434296123e-05,
      "loss": 1.9552,
      "step": 199000
    },
    {
      "epoch": 7.786885245901639,
      "grad_norm": 0.23571285605430603,
      "learning_rate": 3.702764767109029e-05,
      "loss": 1.9557,
      "step": 199500
    },
    {
      "epoch": 7.8064012490242,
      "grad_norm": 0.22377566993236542,
      "learning_rate": 3.69951860525631e-05,
      "loss": 1.956,
      "step": 200000
    },
    {
      "epoch": 7.8064012490242,
      "eval_loss": 1.947828769683838,
      "eval_runtime": 191.0966,
      "eval_samples_per_second": 39224.049,
      "eval_steps_per_second": 19.153,
      "step": 200000
    },
    {
      "epoch": 7.825917252146761,
      "grad_norm": 0.23617322742938995,
      "learning_rate": 3.6962659380692174e-05,
      "loss": 1.956,
      "step": 200500
    },
    {
      "epoch": 7.845433255269321,
      "grad_norm": 0.22801049053668976,
      "learning_rate": 3.6930132708821234e-05,
      "loss": 1.9556,
      "step": 201000
    },
    {
      "epoch": 7.864949258391881,
      "grad_norm": 0.22175933420658112,
      "learning_rate": 3.68976060369503e-05,
      "loss": 1.9557,
      "step": 201500
    },
    {
      "epoch": 7.884465261514442,
      "grad_norm": 0.21840399503707886,
      "learning_rate": 3.686514441842311e-05,
      "loss": 1.9554,
      "step": 202000
    },
    {
      "epoch": 7.884465261514442,
      "eval_loss": 1.9476885795593262,
      "eval_runtime": 192.9646,
      "eval_samples_per_second": 38844.339,
      "eval_steps_per_second": 18.967,
      "step": 202000
    },
    {
      "epoch": 7.903981264637002,
      "grad_norm": 0.24907186627388,
      "learning_rate": 3.683261774655217e-05,
      "loss": 1.9551,
      "step": 202500
    },
    {
      "epoch": 7.923497267759563,
      "grad_norm": 0.2317826747894287,
      "learning_rate": 3.6800091074681244e-05,
      "loss": 1.955,
      "step": 203000
    },
    {
      "epoch": 7.9430132708821235,
      "grad_norm": 0.23917518556118011,
      "learning_rate": 3.6767564402810304e-05,
      "loss": 1.9552,
      "step": 203500
    },
    {
      "epoch": 7.962529274004684,
      "grad_norm": 0.236801877617836,
      "learning_rate": 3.673510278428311e-05,
      "loss": 1.9565,
      "step": 204000
    },
    {
      "epoch": 7.962529274004684,
      "eval_loss": 1.9476230144500732,
      "eval_runtime": 190.3544,
      "eval_samples_per_second": 39376.986,
      "eval_steps_per_second": 19.227,
      "step": 204000
    },
    {
      "epoch": 7.982045277127244,
      "grad_norm": 0.2244330197572708,
      "learning_rate": 3.670257611241218e-05,
      "loss": 1.955,
      "step": 204500
    },
    {
      "epoch": 8.001561280249804,
      "grad_norm": 0.2481093406677246,
      "learning_rate": 3.667004944054124e-05,
      "loss": 1.9545,
      "step": 205000
    },
    {
      "epoch": 8.021077283372366,
      "grad_norm": 0.23193222284317017,
      "learning_rate": 3.6637522768670314e-05,
      "loss": 1.9561,
      "step": 205500
    },
    {
      "epoch": 8.040593286494925,
      "grad_norm": 0.23492616415023804,
      "learning_rate": 3.660506115014312e-05,
      "loss": 1.9549,
      "step": 206000
    },
    {
      "epoch": 8.040593286494925,
      "eval_loss": 1.9476025104522705,
      "eval_runtime": 190.3103,
      "eval_samples_per_second": 39386.12,
      "eval_steps_per_second": 19.232,
      "step": 206000
    },
    {
      "epoch": 8.060109289617486,
      "grad_norm": 0.23268219828605652,
      "learning_rate": 3.657259953161592e-05,
      "loss": 1.9548,
      "step": 206500
    },
    {
      "epoch": 8.079625292740047,
      "grad_norm": 0.2559655010700226,
      "learning_rate": 3.6540072859745e-05,
      "loss": 1.9546,
      "step": 207000
    },
    {
      "epoch": 8.099141295862607,
      "grad_norm": 0.22009596228599548,
      "learning_rate": 3.650754618787406e-05,
      "loss": 1.955,
      "step": 207500
    },
    {
      "epoch": 8.118657298985168,
      "grad_norm": 0.2484300136566162,
      "learning_rate": 3.6475019516003125e-05,
      "loss": 1.9557,
      "step": 208000
    },
    {
      "epoch": 8.118657298985168,
      "eval_loss": 1.9472218751907349,
      "eval_runtime": 193.0467,
      "eval_samples_per_second": 38827.824,
      "eval_steps_per_second": 18.959,
      "step": 208000
    },
    {
      "epoch": 8.13817330210773,
      "grad_norm": 0.2331104874610901,
      "learning_rate": 3.644249284413219e-05,
      "loss": 1.9552,
      "step": 208500
    },
    {
      "epoch": 8.157689305230289,
      "grad_norm": 0.22365501523017883,
      "learning_rate": 3.640996617226126e-05,
      "loss": 1.9544,
      "step": 209000
    },
    {
      "epoch": 8.17720530835285,
      "grad_norm": 0.23882393538951874,
      "learning_rate": 3.637743950039032e-05,
      "loss": 1.9557,
      "step": 209500
    },
    {
      "epoch": 8.19672131147541,
      "grad_norm": 0.22624002397060394,
      "learning_rate": 3.6344912828519387e-05,
      "loss": 1.9549,
      "step": 210000
    },
    {
      "epoch": 8.19672131147541,
      "eval_loss": 1.9473748207092285,
      "eval_runtime": 192.2887,
      "eval_samples_per_second": 38980.875,
      "eval_steps_per_second": 19.034,
      "step": 210000
    },
    {
      "epoch": 8.21623731459797,
      "grad_norm": 0.2264137864112854,
      "learning_rate": 3.6312451209992194e-05,
      "loss": 1.9549,
      "step": 210500
    },
    {
      "epoch": 8.235753317720532,
      "grad_norm": 0.2254534363746643,
      "learning_rate": 3.627992453812126e-05,
      "loss": 1.9548,
      "step": 211000
    },
    {
      "epoch": 8.255269320843091,
      "grad_norm": 0.23662246763706207,
      "learning_rate": 3.624739786625033e-05,
      "loss": 1.9549,
      "step": 211500
    },
    {
      "epoch": 8.274785323965652,
      "grad_norm": 0.2442811280488968,
      "learning_rate": 3.621487119437939e-05,
      "loss": 1.9554,
      "step": 212000
    },
    {
      "epoch": 8.274785323965652,
      "eval_loss": 1.947183609008789,
      "eval_runtime": 190.2068,
      "eval_samples_per_second": 39407.554,
      "eval_steps_per_second": 19.242,
      "step": 212000
    },
    {
      "epoch": 8.294301327088212,
      "grad_norm": 0.21456606686115265,
      "learning_rate": 3.61824095758522e-05,
      "loss": 1.9545,
      "step": 212500
    },
    {
      "epoch": 8.313817330210773,
      "grad_norm": 0.23363900184631348,
      "learning_rate": 3.6149882903981264e-05,
      "loss": 1.9549,
      "step": 213000
    },
    {
      "epoch": 8.333333333333334,
      "grad_norm": 0.22591887414455414,
      "learning_rate": 3.611735623211033e-05,
      "loss": 1.9553,
      "step": 213500
    },
    {
      "epoch": 8.352849336455893,
      "grad_norm": 0.226268008351326,
      "learning_rate": 3.60848295602394e-05,
      "loss": 1.955,
      "step": 214000
    },
    {
      "epoch": 8.352849336455893,
      "eval_loss": 1.9470996856689453,
      "eval_runtime": 191.5186,
      "eval_samples_per_second": 39137.624,
      "eval_steps_per_second": 19.11,
      "step": 214000
    },
    {
      "epoch": 8.372365339578455,
      "grad_norm": 0.23084118962287903,
      "learning_rate": 3.605236794171221e-05,
      "loss": 1.955,
      "step": 214500
    },
    {
      "epoch": 8.391881342701016,
      "grad_norm": 0.22079847753047943,
      "learning_rate": 3.601984126984127e-05,
      "loss": 1.9552,
      "step": 215000
    },
    {
      "epoch": 8.411397345823575,
      "grad_norm": 0.23049427568912506,
      "learning_rate": 3.598731459797034e-05,
      "loss": 1.9547,
      "step": 215500
    },
    {
      "epoch": 8.430913348946136,
      "grad_norm": 0.23148134350776672,
      "learning_rate": 3.59547879260994e-05,
      "loss": 1.9551,
      "step": 216000
    },
    {
      "epoch": 8.430913348946136,
      "eval_loss": 1.946834683418274,
      "eval_runtime": 192.3813,
      "eval_samples_per_second": 38962.117,
      "eval_steps_per_second": 19.025,
      "step": 216000
    },
    {
      "epoch": 8.450429352068696,
      "grad_norm": 0.22802986204624176,
      "learning_rate": 3.592232630757221e-05,
      "loss": 1.9541,
      "step": 216500
    },
    {
      "epoch": 8.469945355191257,
      "grad_norm": 0.23755882680416107,
      "learning_rate": 3.588979963570128e-05,
      "loss": 1.9552,
      "step": 217000
    },
    {
      "epoch": 8.489461358313818,
      "grad_norm": 0.2331283986568451,
      "learning_rate": 3.5857272963830344e-05,
      "loss": 1.9547,
      "step": 217500
    },
    {
      "epoch": 8.508977361436378,
      "grad_norm": 0.22561025619506836,
      "learning_rate": 3.582474629195941e-05,
      "loss": 1.9538,
      "step": 218000
    },
    {
      "epoch": 8.508977361436378,
      "eval_loss": 1.9468128681182861,
      "eval_runtime": 190.6418,
      "eval_samples_per_second": 39317.621,
      "eval_steps_per_second": 19.198,
      "step": 218000
    },
    {
      "epoch": 8.528493364558939,
      "grad_norm": 0.25049227476119995,
      "learning_rate": 3.579228467343221e-05,
      "loss": 1.9543,
      "step": 218500
    },
    {
      "epoch": 8.548009367681498,
      "grad_norm": 0.22811058163642883,
      "learning_rate": 3.5759758001561286e-05,
      "loss": 1.9546,
      "step": 219000
    },
    {
      "epoch": 8.56752537080406,
      "grad_norm": 0.21602755784988403,
      "learning_rate": 3.5727231329690347e-05,
      "loss": 1.9547,
      "step": 219500
    },
    {
      "epoch": 8.58704137392662,
      "grad_norm": 0.2569209635257721,
      "learning_rate": 3.5694704657819414e-05,
      "loss": 1.9542,
      "step": 220000
    },
    {
      "epoch": 8.58704137392662,
      "eval_loss": 1.9467214345932007,
      "eval_runtime": 191.761,
      "eval_samples_per_second": 39088.156,
      "eval_steps_per_second": 19.086,
      "step": 220000
    },
    {
      "epoch": 8.60655737704918,
      "grad_norm": 0.2242007851600647,
      "learning_rate": 3.566224303929222e-05,
      "loss": 1.9546,
      "step": 220500
    },
    {
      "epoch": 8.626073380171741,
      "grad_norm": 0.22759924829006195,
      "learning_rate": 3.562971636742129e-05,
      "loss": 1.9542,
      "step": 221000
    },
    {
      "epoch": 8.6455893832943,
      "grad_norm": 0.22116662561893463,
      "learning_rate": 3.5597189695550356e-05,
      "loss": 1.9542,
      "step": 221500
    },
    {
      "epoch": 8.665105386416862,
      "grad_norm": 0.24192778766155243,
      "learning_rate": 3.5564663023679417e-05,
      "loss": 1.9544,
      "step": 222000
    },
    {
      "epoch": 8.665105386416862,
      "eval_loss": 1.946500539779663,
      "eval_runtime": 192.3421,
      "eval_samples_per_second": 38970.056,
      "eval_steps_per_second": 19.029,
      "step": 222000
    },
    {
      "epoch": 8.684621389539423,
      "grad_norm": 0.23287418484687805,
      "learning_rate": 3.5532201405152225e-05,
      "loss": 1.9542,
      "step": 222500
    },
    {
      "epoch": 8.704137392661982,
      "grad_norm": 0.22620175778865814,
      "learning_rate": 3.549967473328129e-05,
      "loss": 1.9546,
      "step": 223000
    },
    {
      "epoch": 8.723653395784543,
      "grad_norm": 0.23829329013824463,
      "learning_rate": 3.546714806141036e-05,
      "loss": 1.9542,
      "step": 223500
    },
    {
      "epoch": 8.743169398907105,
      "grad_norm": 0.22187243402004242,
      "learning_rate": 3.5434621389539426e-05,
      "loss": 1.9552,
      "step": 224000
    },
    {
      "epoch": 8.743169398907105,
      "eval_loss": 1.9464255571365356,
      "eval_runtime": 190.6953,
      "eval_samples_per_second": 39306.594,
      "eval_steps_per_second": 19.193,
      "step": 224000
    },
    {
      "epoch": 8.762685402029664,
      "grad_norm": 0.23546671867370605,
      "learning_rate": 3.5402159771012234e-05,
      "loss": 1.9538,
      "step": 224500
    },
    {
      "epoch": 8.782201405152225,
      "grad_norm": 0.2324487417936325,
      "learning_rate": 3.5369633099141294e-05,
      "loss": 1.9543,
      "step": 225000
    },
    {
      "epoch": 8.801717408274785,
      "grad_norm": 0.22867351770401,
      "learning_rate": 3.533710642727036e-05,
      "loss": 1.9538,
      "step": 225500
    },
    {
      "epoch": 8.821233411397346,
      "grad_norm": 0.23239131271839142,
      "learning_rate": 3.530457975539943e-05,
      "loss": 1.9541,
      "step": 226000
    },
    {
      "epoch": 8.821233411397346,
      "eval_loss": 1.9464151859283447,
      "eval_runtime": 191.2258,
      "eval_samples_per_second": 39197.553,
      "eval_steps_per_second": 19.14,
      "step": 226000
    },
    {
      "epoch": 8.840749414519907,
      "grad_norm": 0.25426357984542847,
      "learning_rate": 3.527211813687224e-05,
      "loss": 1.9534,
      "step": 226500
    },
    {
      "epoch": 8.860265417642466,
      "grad_norm": 0.22155098617076874,
      "learning_rate": 3.5239591465001304e-05,
      "loss": 1.9545,
      "step": 227000
    },
    {
      "epoch": 8.879781420765028,
      "grad_norm": 0.23861484229564667,
      "learning_rate": 3.5207064793130364e-05,
      "loss": 1.9537,
      "step": 227500
    },
    {
      "epoch": 8.899297423887587,
      "grad_norm": 0.2222801297903061,
      "learning_rate": 3.517453812125944e-05,
      "loss": 1.9541,
      "step": 228000
    },
    {
      "epoch": 8.899297423887587,
      "eval_loss": 1.946216344833374,
      "eval_runtime": 192.9946,
      "eval_samples_per_second": 38838.295,
      "eval_steps_per_second": 18.964,
      "step": 228000
    },
    {
      "epoch": 8.918813427010148,
      "grad_norm": 0.22232389450073242,
      "learning_rate": 3.514207650273224e-05,
      "loss": 1.9535,
      "step": 228500
    },
    {
      "epoch": 8.93832943013271,
      "grad_norm": 0.22633330523967743,
      "learning_rate": 3.5109549830861313e-05,
      "loss": 1.9549,
      "step": 229000
    },
    {
      "epoch": 8.957845433255269,
      "grad_norm": 0.2197193205356598,
      "learning_rate": 3.5077023158990374e-05,
      "loss": 1.9542,
      "step": 229500
    },
    {
      "epoch": 8.97736143637783,
      "grad_norm": 0.24047446250915527,
      "learning_rate": 3.504449648711944e-05,
      "loss": 1.9539,
      "step": 230000
    },
    {
      "epoch": 8.97736143637783,
      "eval_loss": 1.9461671113967896,
      "eval_runtime": 190.5331,
      "eval_samples_per_second": 39340.064,
      "eval_steps_per_second": 19.209,
      "step": 230000
    },
    {
      "epoch": 8.996877439500391,
      "grad_norm": 0.23868191242218018,
      "learning_rate": 3.501203486859225e-05,
      "loss": 1.9535,
      "step": 230500
    },
    {
      "epoch": 9.01639344262295,
      "grad_norm": 0.23009894788265228,
      "learning_rate": 3.497950819672131e-05,
      "loss": 1.9534,
      "step": 231000
    },
    {
      "epoch": 9.035909445745512,
      "grad_norm": 0.22839486598968506,
      "learning_rate": 3.4946981524850383e-05,
      "loss": 1.9544,
      "step": 231500
    },
    {
      "epoch": 9.055425448868071,
      "grad_norm": 0.22884352505207062,
      "learning_rate": 3.4914454852979444e-05,
      "loss": 1.9533,
      "step": 232000
    },
    {
      "epoch": 9.055425448868071,
      "eval_loss": 1.9458656311035156,
      "eval_runtime": 191.3707,
      "eval_samples_per_second": 39167.868,
      "eval_steps_per_second": 19.125,
      "step": 232000
    },
    {
      "epoch": 9.074941451990632,
      "grad_norm": 0.22480498254299164,
      "learning_rate": 3.488199323445225e-05,
      "loss": 1.9532,
      "step": 232500
    },
    {
      "epoch": 9.094457455113194,
      "grad_norm": 0.24461647868156433,
      "learning_rate": 3.484946656258132e-05,
      "loss": 1.9539,
      "step": 233000
    },
    {
      "epoch": 9.113973458235753,
      "grad_norm": 0.2264784723520279,
      "learning_rate": 3.481693989071038e-05,
      "loss": 1.9535,
      "step": 233500
    },
    {
      "epoch": 9.133489461358314,
      "grad_norm": 0.22705131769180298,
      "learning_rate": 3.478441321883945e-05,
      "loss": 1.9529,
      "step": 234000
    },
    {
      "epoch": 9.133489461358314,
      "eval_loss": 1.946045994758606,
      "eval_runtime": 192.5612,
      "eval_samples_per_second": 38925.717,
      "eval_steps_per_second": 19.007,
      "step": 234000
    },
    {
      "epoch": 9.153005464480874,
      "grad_norm": 0.22620004415512085,
      "learning_rate": 3.475195160031226e-05,
      "loss": 1.9533,
      "step": 234500
    },
    {
      "epoch": 9.172521467603435,
      "grad_norm": 0.23939494788646698,
      "learning_rate": 3.471942492844132e-05,
      "loss": 1.9538,
      "step": 235000
    },
    {
      "epoch": 9.192037470725996,
      "grad_norm": 0.2248719334602356,
      "learning_rate": 3.468689825657039e-05,
      "loss": 1.9537,
      "step": 235500
    },
    {
      "epoch": 9.211553473848555,
      "grad_norm": 0.23567403852939606,
      "learning_rate": 3.4654371584699456e-05,
      "loss": 1.9531,
      "step": 236000
    },
    {
      "epoch": 9.211553473848555,
      "eval_loss": 1.9459295272827148,
      "eval_runtime": 190.6451,
      "eval_samples_per_second": 39316.951,
      "eval_steps_per_second": 19.198,
      "step": 236000
    },
    {
      "epoch": 9.231069476971117,
      "grad_norm": 0.22951042652130127,
      "learning_rate": 3.4621909966172264e-05,
      "loss": 1.9536,
      "step": 236500
    },
    {
      "epoch": 9.250585480093676,
      "grad_norm": 0.22573882341384888,
      "learning_rate": 3.458938329430133e-05,
      "loss": 1.9538,
      "step": 237000
    },
    {
      "epoch": 9.270101483216237,
      "grad_norm": 0.2313586175441742,
      "learning_rate": 3.455685662243039e-05,
      "loss": 1.9529,
      "step": 237500
    },
    {
      "epoch": 9.289617486338798,
      "grad_norm": 0.24359169602394104,
      "learning_rate": 3.452432995055946e-05,
      "loss": 1.9531,
      "step": 238000
    },
    {
      "epoch": 9.289617486338798,
      "eval_loss": 1.9460208415985107,
      "eval_runtime": 191.5579,
      "eval_samples_per_second": 39129.6,
      "eval_steps_per_second": 19.106,
      "step": 238000
    },
    {
      "epoch": 9.309133489461358,
      "grad_norm": 0.23559823632240295,
      "learning_rate": 3.449193338537601e-05,
      "loss": 1.9534,
      "step": 238500
    },
    {
      "epoch": 9.328649492583919,
      "grad_norm": 0.2154042273759842,
      "learning_rate": 3.4459406713505075e-05,
      "loss": 1.953,
      "step": 239000
    },
    {
      "epoch": 9.34816549570648,
      "grad_norm": 0.2371170073747635,
      "learning_rate": 3.442688004163414e-05,
      "loss": 1.9534,
      "step": 239500
    },
    {
      "epoch": 9.36768149882904,
      "grad_norm": 0.22803246974945068,
      "learning_rate": 3.43943533697632e-05,
      "loss": 1.9538,
      "step": 240000
    },
    {
      "epoch": 9.36768149882904,
      "eval_loss": 1.9455783367156982,
      "eval_runtime": 192.7309,
      "eval_samples_per_second": 38891.437,
      "eval_steps_per_second": 18.99,
      "step": 240000
    },
    {
      "epoch": 9.3871975019516,
      "grad_norm": 0.23034211993217468,
      "learning_rate": 3.4361826697892276e-05,
      "loss": 1.9529,
      "step": 240500
    },
    {
      "epoch": 9.40671350507416,
      "grad_norm": 0.22783999145030975,
      "learning_rate": 3.432930002602134e-05,
      "loss": 1.953,
      "step": 241000
    },
    {
      "epoch": 9.426229508196721,
      "grad_norm": 0.23397286236286163,
      "learning_rate": 3.429677335415041e-05,
      "loss": 1.9538,
      "step": 241500
    },
    {
      "epoch": 9.445745511319283,
      "grad_norm": 0.2513030767440796,
      "learning_rate": 3.426424668227947e-05,
      "loss": 1.9536,
      "step": 242000
    },
    {
      "epoch": 9.445745511319283,
      "eval_loss": 1.9456707239151,
      "eval_runtime": 191.6836,
      "eval_samples_per_second": 39103.933,
      "eval_steps_per_second": 19.094,
      "step": 242000
    },
    {
      "epoch": 9.465261514441842,
      "grad_norm": 0.23260563611984253,
      "learning_rate": 3.423178506375228e-05,
      "loss": 1.953,
      "step": 242500
    },
    {
      "epoch": 9.484777517564403,
      "grad_norm": 0.22980894148349762,
      "learning_rate": 3.4199258391881346e-05,
      "loss": 1.9531,
      "step": 243000
    },
    {
      "epoch": 9.504293520686963,
      "grad_norm": 0.2378019392490387,
      "learning_rate": 3.416673172001041e-05,
      "loss": 1.953,
      "step": 243500
    },
    {
      "epoch": 9.523809523809524,
      "grad_norm": 0.24993181228637695,
      "learning_rate": 3.413420504813948e-05,
      "loss": 1.9531,
      "step": 244000
    },
    {
      "epoch": 9.523809523809524,
      "eval_loss": 1.9454829692840576,
      "eval_runtime": 193.1539,
      "eval_samples_per_second": 38806.266,
      "eval_steps_per_second": 18.949,
      "step": 244000
    },
    {
      "epoch": 9.543325526932085,
      "grad_norm": 0.21589124202728271,
      "learning_rate": 3.410174342961228e-05,
      "loss": 1.9537,
      "step": 244500
    },
    {
      "epoch": 9.562841530054644,
      "grad_norm": 0.23827199637889862,
      "learning_rate": 3.406921675774135e-05,
      "loss": 1.9532,
      "step": 245000
    },
    {
      "epoch": 9.582357533177206,
      "grad_norm": 0.23271377384662628,
      "learning_rate": 3.4036690085870416e-05,
      "loss": 1.9528,
      "step": 245500
    },
    {
      "epoch": 9.601873536299767,
      "grad_norm": 0.23140712082386017,
      "learning_rate": 3.400416341399948e-05,
      "loss": 1.9533,
      "step": 246000
    },
    {
      "epoch": 9.601873536299767,
      "eval_loss": 1.9453439712524414,
      "eval_runtime": 192.9772,
      "eval_samples_per_second": 38841.811,
      "eval_steps_per_second": 18.966,
      "step": 246000
    },
    {
      "epoch": 9.621389539422326,
      "grad_norm": 0.22522008419036865,
      "learning_rate": 3.397170179547229e-05,
      "loss": 1.9527,
      "step": 246500
    },
    {
      "epoch": 9.640905542544887,
      "grad_norm": 0.23335711658000946,
      "learning_rate": 3.393917512360135e-05,
      "loss": 1.9536,
      "step": 247000
    },
    {
      "epoch": 9.660421545667447,
      "grad_norm": 0.23555174469947815,
      "learning_rate": 3.390664845173042e-05,
      "loss": 1.9531,
      "step": 247500
    },
    {
      "epoch": 9.679937548790008,
      "grad_norm": 0.2482844889163971,
      "learning_rate": 3.3874121779859486e-05,
      "loss": 1.9532,
      "step": 248000
    },
    {
      "epoch": 9.679937548790008,
      "eval_loss": 1.9453235864639282,
      "eval_runtime": 192.5296,
      "eval_samples_per_second": 38932.103,
      "eval_steps_per_second": 19.01,
      "step": 248000
    },
    {
      "epoch": 9.699453551912569,
      "grad_norm": 0.22799308598041534,
      "learning_rate": 3.3841660161332294e-05,
      "loss": 1.9536,
      "step": 248500
    },
    {
      "epoch": 9.718969555035128,
      "grad_norm": 0.23196709156036377,
      "learning_rate": 3.380913348946136e-05,
      "loss": 1.9532,
      "step": 249000
    },
    {
      "epoch": 9.73848555815769,
      "grad_norm": 0.22850482165813446,
      "learning_rate": 3.377660681759043e-05,
      "loss": 1.9532,
      "step": 249500
    },
    {
      "epoch": 9.758001561280249,
      "grad_norm": 0.22459906339645386,
      "learning_rate": 3.374408014571949e-05,
      "loss": 1.9534,
      "step": 250000
    },
    {
      "epoch": 9.758001561280249,
      "eval_loss": 1.945314645767212,
      "eval_runtime": 193.9962,
      "eval_samples_per_second": 38637.774,
      "eval_steps_per_second": 18.866,
      "step": 250000
    },
    {
      "epoch": 9.77751756440281,
      "grad_norm": 0.22169284522533417,
      "learning_rate": 3.3711618527192304e-05,
      "loss": 1.9534,
      "step": 250500
    },
    {
      "epoch": 9.797033567525371,
      "grad_norm": 0.22581233084201813,
      "learning_rate": 3.3679091855321364e-05,
      "loss": 1.9525,
      "step": 251000
    },
    {
      "epoch": 9.81654957064793,
      "grad_norm": 0.24300839006900787,
      "learning_rate": 3.364656518345043e-05,
      "loss": 1.9536,
      "step": 251500
    },
    {
      "epoch": 9.836065573770492,
      "grad_norm": 0.2446785271167755,
      "learning_rate": 3.36140385115795e-05,
      "loss": 1.9532,
      "step": 252000
    },
    {
      "epoch": 9.836065573770492,
      "eval_loss": 1.9451972246170044,
      "eval_runtime": 191.7277,
      "eval_samples_per_second": 39094.936,
      "eval_steps_per_second": 19.09,
      "step": 252000
    },
    {
      "epoch": 9.855581576893051,
      "grad_norm": 0.2285919189453125,
      "learning_rate": 3.35815768930523e-05,
      "loss": 1.9531,
      "step": 252500
    },
    {
      "epoch": 9.875097580015613,
      "grad_norm": 0.22652113437652588,
      "learning_rate": 3.3549050221181374e-05,
      "loss": 1.953,
      "step": 253000
    },
    {
      "epoch": 9.894613583138174,
      "grad_norm": 0.22538381814956665,
      "learning_rate": 3.3516523549310434e-05,
      "loss": 1.9527,
      "step": 253500
    },
    {
      "epoch": 9.914129586260733,
      "grad_norm": 0.22823582589626312,
      "learning_rate": 3.34839968774395e-05,
      "loss": 1.9532,
      "step": 254000
    },
    {
      "epoch": 9.914129586260733,
      "eval_loss": 1.945062279701233,
      "eval_runtime": 192.4744,
      "eval_samples_per_second": 38943.278,
      "eval_steps_per_second": 19.016,
      "step": 254000
    },
    {
      "epoch": 9.933645589383294,
      "grad_norm": 0.220706969499588,
      "learning_rate": 3.345153525891231e-05,
      "loss": 1.9528,
      "step": 254500
    },
    {
      "epoch": 9.953161592505854,
      "grad_norm": 0.23488114774227142,
      "learning_rate": 3.3419008587041376e-05,
      "loss": 1.9531,
      "step": 255000
    },
    {
      "epoch": 9.972677595628415,
      "grad_norm": 0.22651983797550201,
      "learning_rate": 3.3386481915170444e-05,
      "loss": 1.9523,
      "step": 255500
    },
    {
      "epoch": 9.992193598750976,
      "grad_norm": 0.25369107723236084,
      "learning_rate": 3.3353955243299504e-05,
      "loss": 1.9526,
      "step": 256000
    },
    {
      "epoch": 9.992193598750976,
      "eval_loss": 1.9451661109924316,
      "eval_runtime": 193.4991,
      "eval_samples_per_second": 38737.039,
      "eval_steps_per_second": 18.915,
      "step": 256000
    },
    {
      "epoch": 10.011709601873536,
      "grad_norm": 0.23861117660999298,
      "learning_rate": 3.332149362477232e-05,
      "loss": 1.9527,
      "step": 256500
    },
    {
      "epoch": 10.031225604996097,
      "grad_norm": 0.22051820158958435,
      "learning_rate": 3.328896695290138e-05,
      "loss": 1.9523,
      "step": 257000
    },
    {
      "epoch": 10.050741608118658,
      "grad_norm": 0.21986299753189087,
      "learning_rate": 3.3256440281030446e-05,
      "loss": 1.9526,
      "step": 257500
    },
    {
      "epoch": 10.070257611241217,
      "grad_norm": 0.22887657582759857,
      "learning_rate": 3.3223913609159513e-05,
      "loss": 1.9527,
      "step": 258000
    },
    {
      "epoch": 10.070257611241217,
      "eval_loss": 1.945099949836731,
      "eval_runtime": 191.5243,
      "eval_samples_per_second": 39136.462,
      "eval_steps_per_second": 19.11,
      "step": 258000
    },
    {
      "epoch": 10.089773614363779,
      "grad_norm": 0.22085152566432953,
      "learning_rate": 3.319145199063232e-05,
      "loss": 1.952,
      "step": 258500
    },
    {
      "epoch": 10.109289617486338,
      "grad_norm": 0.2159210741519928,
      "learning_rate": 3.315892531876139e-05,
      "loss": 1.9525,
      "step": 259000
    },
    {
      "epoch": 10.1288056206089,
      "grad_norm": 0.22975023090839386,
      "learning_rate": 3.312639864689045e-05,
      "loss": 1.9519,
      "step": 259500
    },
    {
      "epoch": 10.14832162373146,
      "grad_norm": 0.23030215501785278,
      "learning_rate": 3.3093871975019516e-05,
      "loss": 1.9519,
      "step": 260000
    },
    {
      "epoch": 10.14832162373146,
      "eval_loss": 1.9450254440307617,
      "eval_runtime": 193.4749,
      "eval_samples_per_second": 38741.897,
      "eval_steps_per_second": 18.917,
      "step": 260000
    },
    {
      "epoch": 10.16783762685402,
      "grad_norm": 0.22407495975494385,
      "learning_rate": 3.3061345303148583e-05,
      "loss": 1.9525,
      "step": 260500
    },
    {
      "epoch": 10.187353629976581,
      "grad_norm": 0.222517192363739,
      "learning_rate": 3.302888368462139e-05,
      "loss": 1.9525,
      "step": 261000
    },
    {
      "epoch": 10.206869633099142,
      "grad_norm": 0.2326257973909378,
      "learning_rate": 3.299635701275046e-05,
      "loss": 1.9529,
      "step": 261500
    },
    {
      "epoch": 10.226385636221702,
      "grad_norm": 0.23802508413791656,
      "learning_rate": 3.296383034087952e-05,
      "loss": 1.9523,
      "step": 262000
    },
    {
      "epoch": 10.226385636221702,
      "eval_loss": 1.9447320699691772,
      "eval_runtime": 191.6881,
      "eval_samples_per_second": 39103.017,
      "eval_steps_per_second": 19.094,
      "step": 262000
    },
    {
      "epoch": 10.245901639344263,
      "grad_norm": 0.2303425520658493,
      "learning_rate": 3.293130366900859e-05,
      "loss": 1.9523,
      "step": 262500
    },
    {
      "epoch": 10.265417642466822,
      "grad_norm": 0.24889244139194489,
      "learning_rate": 3.289890710382514e-05,
      "loss": 1.9522,
      "step": 263000
    },
    {
      "epoch": 10.284933645589383,
      "grad_norm": 0.2113088071346283,
      "learning_rate": 3.28663804319542e-05,
      "loss": 1.9526,
      "step": 263500
    },
    {
      "epoch": 10.304449648711945,
      "grad_norm": 0.22429654002189636,
      "learning_rate": 3.283385376008327e-05,
      "loss": 1.9514,
      "step": 264000
    },
    {
      "epoch": 10.304449648711945,
      "eval_loss": 1.9447314739227295,
      "eval_runtime": 192.3503,
      "eval_samples_per_second": 38968.405,
      "eval_steps_per_second": 19.028,
      "step": 264000
    },
    {
      "epoch": 10.323965651834504,
      "grad_norm": 0.2308320254087448,
      "learning_rate": 3.2801327088212336e-05,
      "loss": 1.9522,
      "step": 264500
    },
    {
      "epoch": 10.343481654957065,
      "grad_norm": 0.43565675616264343,
      "learning_rate": 3.27688004163414e-05,
      "loss": 1.9524,
      "step": 265000
    },
    {
      "epoch": 10.362997658079625,
      "grad_norm": 0.23061324656009674,
      "learning_rate": 3.273627374447047e-05,
      "loss": 1.952,
      "step": 265500
    },
    {
      "epoch": 10.382513661202186,
      "grad_norm": 0.23464305698871613,
      "learning_rate": 3.270374707259953e-05,
      "loss": 1.9523,
      "step": 266000
    },
    {
      "epoch": 10.382513661202186,
      "eval_loss": 1.9445935487747192,
      "eval_runtime": 193.7605,
      "eval_samples_per_second": 38684.782,
      "eval_steps_per_second": 18.889,
      "step": 266000
    },
    {
      "epoch": 10.402029664324747,
      "grad_norm": 0.22588898241519928,
      "learning_rate": 3.26712204007286e-05,
      "loss": 1.9523,
      "step": 266500
    },
    {
      "epoch": 10.421545667447306,
      "grad_norm": 0.22594551742076874,
      "learning_rate": 3.2638758782201406e-05,
      "loss": 1.9523,
      "step": 267000
    },
    {
      "epoch": 10.441061670569868,
      "grad_norm": 0.23206502199172974,
      "learning_rate": 3.2606232110330474e-05,
      "loss": 1.9519,
      "step": 267500
    },
    {
      "epoch": 10.460577673692427,
      "grad_norm": 0.2354602962732315,
      "learning_rate": 3.257370543845954e-05,
      "loss": 1.9521,
      "step": 268000
    },
    {
      "epoch": 10.460577673692427,
      "eval_loss": 1.9445072412490845,
      "eval_runtime": 191.4934,
      "eval_samples_per_second": 39142.766,
      "eval_steps_per_second": 19.113,
      "step": 268000
    },
    {
      "epoch": 10.480093676814988,
      "grad_norm": 0.23569126427173615,
      "learning_rate": 3.25411787665886e-05,
      "loss": 1.9518,
      "step": 268500
    },
    {
      "epoch": 10.49960967993755,
      "grad_norm": 0.22482560575008392,
      "learning_rate": 3.2508717148061416e-05,
      "loss": 1.952,
      "step": 269000
    },
    {
      "epoch": 10.519125683060109,
      "grad_norm": 0.23738114535808563,
      "learning_rate": 3.2476190476190476e-05,
      "loss": 1.9515,
      "step": 269500
    },
    {
      "epoch": 10.53864168618267,
      "grad_norm": 0.23263047635555267,
      "learning_rate": 3.2443663804319544e-05,
      "loss": 1.9518,
      "step": 270000
    },
    {
      "epoch": 10.53864168618267,
      "eval_loss": 1.9443129301071167,
      "eval_runtime": 194.5065,
      "eval_samples_per_second": 38536.41,
      "eval_steps_per_second": 18.817,
      "step": 270000
    },
    {
      "epoch": 10.55815768930523,
      "grad_norm": 0.2574577033519745,
      "learning_rate": 3.241113713244861e-05,
      "loss": 1.9524,
      "step": 270500
    },
    {
      "epoch": 10.57767369242779,
      "grad_norm": 0.2435230314731598,
      "learning_rate": 3.237867551392142e-05,
      "loss": 1.9519,
      "step": 271000
    },
    {
      "epoch": 10.597189695550352,
      "grad_norm": 0.23095758259296417,
      "learning_rate": 3.2346148842050486e-05,
      "loss": 1.9522,
      "step": 271500
    },
    {
      "epoch": 10.616705698672911,
      "grad_norm": 0.2423647940158844,
      "learning_rate": 3.2313622170179546e-05,
      "loss": 1.9524,
      "step": 272000
    },
    {
      "epoch": 10.616705698672911,
      "eval_loss": 1.9442744255065918,
      "eval_runtime": 191.5717,
      "eval_samples_per_second": 39126.784,
      "eval_steps_per_second": 19.105,
      "step": 272000
    },
    {
      "epoch": 10.636221701795472,
      "grad_norm": 0.24076677858829498,
      "learning_rate": 3.2281095498308613e-05,
      "loss": 1.9527,
      "step": 272500
    },
    {
      "epoch": 10.655737704918034,
      "grad_norm": 0.23537710309028625,
      "learning_rate": 3.224856882643768e-05,
      "loss": 1.9512,
      "step": 273000
    },
    {
      "epoch": 10.675253708040593,
      "grad_norm": 0.2386542707681656,
      "learning_rate": 3.221604215456675e-05,
      "loss": 1.9517,
      "step": 273500
    },
    {
      "epoch": 10.694769711163154,
      "grad_norm": 0.21459996700286865,
      "learning_rate": 3.2183515482695815e-05,
      "loss": 1.952,
      "step": 274000
    },
    {
      "epoch": 10.694769711163154,
      "eval_loss": 1.9442243576049805,
      "eval_runtime": 192.6631,
      "eval_samples_per_second": 38905.13,
      "eval_steps_per_second": 18.997,
      "step": 274000
    },
    {
      "epoch": 10.714285714285714,
      "grad_norm": 0.24601033329963684,
      "learning_rate": 3.2150988810824875e-05,
      "loss": 1.9506,
      "step": 274500
    },
    {
      "epoch": 10.733801717408275,
      "grad_norm": 0.2578894793987274,
      "learning_rate": 3.211852719229769e-05,
      "loss": 1.9517,
      "step": 275000
    },
    {
      "epoch": 10.753317720530836,
      "grad_norm": 0.22901113331317902,
      "learning_rate": 3.208600052042675e-05,
      "loss": 1.9524,
      "step": 275500
    },
    {
      "epoch": 10.772833723653395,
      "grad_norm": 0.2154930979013443,
      "learning_rate": 3.205347384855582e-05,
      "loss": 1.9515,
      "step": 276000
    },
    {
      "epoch": 10.772833723653395,
      "eval_loss": 1.9441579580307007,
      "eval_runtime": 191.2168,
      "eval_samples_per_second": 39199.389,
      "eval_steps_per_second": 19.141,
      "step": 276000
    },
    {
      "epoch": 10.792349726775956,
      "grad_norm": 0.23080453276634216,
      "learning_rate": 3.2020947176684885e-05,
      "loss": 1.952,
      "step": 276500
    },
    {
      "epoch": 10.811865729898518,
      "grad_norm": 0.22586441040039062,
      "learning_rate": 3.1988485558157686e-05,
      "loss": 1.9522,
      "step": 277000
    },
    {
      "epoch": 10.831381733021077,
      "grad_norm": 0.22679124772548676,
      "learning_rate": 3.195595888628676e-05,
      "loss": 1.9525,
      "step": 277500
    },
    {
      "epoch": 10.850897736143638,
      "grad_norm": 0.21928822994232178,
      "learning_rate": 3.192343221441582e-05,
      "loss": 1.9519,
      "step": 278000
    },
    {
      "epoch": 10.850897736143638,
      "eval_loss": 1.9440749883651733,
      "eval_runtime": 192.4051,
      "eval_samples_per_second": 38957.308,
      "eval_steps_per_second": 19.022,
      "step": 278000
    },
    {
      "epoch": 10.870413739266198,
      "grad_norm": 0.23506568372249603,
      "learning_rate": 3.189090554254489e-05,
      "loss": 1.952,
      "step": 278500
    },
    {
      "epoch": 10.889929742388759,
      "grad_norm": 0.23552435636520386,
      "learning_rate": 3.1858443924017696e-05,
      "loss": 1.9518,
      "step": 279000
    },
    {
      "epoch": 10.90944574551132,
      "grad_norm": 0.22570940852165222,
      "learning_rate": 3.182591725214676e-05,
      "loss": 1.9516,
      "step": 279500
    },
    {
      "epoch": 10.92896174863388,
      "grad_norm": 0.22884155809879303,
      "learning_rate": 3.179339058027583e-05,
      "loss": 1.9519,
      "step": 280000
    },
    {
      "epoch": 10.92896174863388,
      "eval_loss": 1.9438986778259277,
      "eval_runtime": 193.383,
      "eval_samples_per_second": 38760.293,
      "eval_steps_per_second": 18.926,
      "step": 280000
    },
    {
      "epoch": 10.94847775175644,
      "grad_norm": 0.2330639511346817,
      "learning_rate": 3.176086390840489e-05,
      "loss": 1.9514,
      "step": 280500
    },
    {
      "epoch": 10.967993754879,
      "grad_norm": 0.21267621219158173,
      "learning_rate": 3.17284022898777e-05,
      "loss": 1.9515,
      "step": 281000
    },
    {
      "epoch": 10.987509758001561,
      "grad_norm": 0.2355296015739441,
      "learning_rate": 3.169594067135051e-05,
      "loss": 1.9507,
      "step": 281500
    },
    {
      "epoch": 11.007025761124122,
      "grad_norm": 0.21542412042617798,
      "learning_rate": 3.1663413999479574e-05,
      "loss": 1.9515,
      "step": 282000
    },
    {
      "epoch": 11.007025761124122,
      "eval_loss": 1.9439749717712402,
      "eval_runtime": 191.4466,
      "eval_samples_per_second": 39152.334,
      "eval_steps_per_second": 19.118,
      "step": 282000
    },
    {
      "epoch": 11.026541764246682,
      "grad_norm": 0.23278139531612396,
      "learning_rate": 3.163088732760864e-05,
      "loss": 1.952,
      "step": 282500
    },
    {
      "epoch": 11.046057767369243,
      "grad_norm": 0.22240136563777924,
      "learning_rate": 3.159836065573771e-05,
      "loss": 1.9508,
      "step": 283000
    },
    {
      "epoch": 11.065573770491802,
      "grad_norm": 0.22888530790805817,
      "learning_rate": 3.156583398386677e-05,
      "loss": 1.9507,
      "step": 283500
    },
    {
      "epoch": 11.085089773614364,
      "grad_norm": 0.2291540652513504,
      "learning_rate": 3.1533307311995836e-05,
      "loss": 1.9502,
      "step": 284000
    },
    {
      "epoch": 11.085089773614364,
      "eval_loss": 1.9438351392745972,
      "eval_runtime": 194.3325,
      "eval_samples_per_second": 38570.922,
      "eval_steps_per_second": 18.834,
      "step": 284000
    },
    {
      "epoch": 11.104605776736925,
      "grad_norm": 0.23381586372852325,
      "learning_rate": 3.15007806401249e-05,
      "loss": 1.9513,
      "step": 284500
    },
    {
      "epoch": 11.124121779859484,
      "grad_norm": 0.22352160513401031,
      "learning_rate": 3.146825396825397e-05,
      "loss": 1.9511,
      "step": 285000
    },
    {
      "epoch": 11.143637782982045,
      "grad_norm": 0.24662788212299347,
      "learning_rate": 3.143579234972678e-05,
      "loss": 1.9511,
      "step": 285500
    },
    {
      "epoch": 11.163153786104607,
      "grad_norm": 0.21839340031147003,
      "learning_rate": 3.1403265677855845e-05,
      "loss": 1.9514,
      "step": 286000
    },
    {
      "epoch": 11.163153786104607,
      "eval_loss": 1.9436445236206055,
      "eval_runtime": 191.648,
      "eval_samples_per_second": 39111.198,
      "eval_steps_per_second": 19.098,
      "step": 286000
    },
    {
      "epoch": 11.182669789227166,
      "grad_norm": 0.2437049299478531,
      "learning_rate": 3.137073900598491e-05,
      "loss": 1.9511,
      "step": 286500
    },
    {
      "epoch": 11.202185792349727,
      "grad_norm": 0.24039244651794434,
      "learning_rate": 3.133821233411397e-05,
      "loss": 1.9512,
      "step": 287000
    },
    {
      "epoch": 11.221701795472287,
      "grad_norm": 0.2086511254310608,
      "learning_rate": 3.130575071558679e-05,
      "loss": 1.951,
      "step": 287500
    },
    {
      "epoch": 11.241217798594848,
      "grad_norm": 0.23914740979671478,
      "learning_rate": 3.127322404371585e-05,
      "loss": 1.9525,
      "step": 288000
    },
    {
      "epoch": 11.241217798594848,
      "eval_loss": 1.9435322284698486,
      "eval_runtime": 194.7153,
      "eval_samples_per_second": 38495.088,
      "eval_steps_per_second": 18.797,
      "step": 288000
    },
    {
      "epoch": 11.260733801717409,
      "grad_norm": 0.22863270342350006,
      "learning_rate": 3.1240697371844915e-05,
      "loss": 1.9511,
      "step": 288500
    },
    {
      "epoch": 11.280249804839968,
      "grad_norm": 0.22167372703552246,
      "learning_rate": 3.120817069997398e-05,
      "loss": 1.9517,
      "step": 289000
    },
    {
      "epoch": 11.29976580796253,
      "grad_norm": 0.23566298186779022,
      "learning_rate": 3.117570908144678e-05,
      "loss": 1.9508,
      "step": 289500
    },
    {
      "epoch": 11.319281811085089,
      "grad_norm": 0.22882701456546783,
      "learning_rate": 3.114318240957586e-05,
      "loss": 1.9511,
      "step": 290000
    },
    {
      "epoch": 11.319281811085089,
      "eval_loss": 1.9437271356582642,
      "eval_runtime": 191.876,
      "eval_samples_per_second": 39064.731,
      "eval_steps_per_second": 19.075,
      "step": 290000
    },
    {
      "epoch": 11.33879781420765,
      "grad_norm": 0.21575354039669037,
      "learning_rate": 3.111065573770492e-05,
      "loss": 1.9508,
      "step": 290500
    },
    {
      "epoch": 11.358313817330211,
      "grad_norm": 0.2281835973262787,
      "learning_rate": 3.1078129065833985e-05,
      "loss": 1.9511,
      "step": 291000
    },
    {
      "epoch": 11.37782982045277,
      "grad_norm": 0.24571599066257477,
      "learning_rate": 3.104566744730679e-05,
      "loss": 1.9521,
      "step": 291500
    },
    {
      "epoch": 11.397345823575332,
      "grad_norm": 0.2187420278787613,
      "learning_rate": 3.101314077543586e-05,
      "loss": 1.9511,
      "step": 292000
    },
    {
      "epoch": 11.397345823575332,
      "eval_loss": 1.9435690641403198,
      "eval_runtime": 192.7149,
      "eval_samples_per_second": 38894.674,
      "eval_steps_per_second": 18.992,
      "step": 292000
    },
    {
      "epoch": 11.416861826697893,
      "grad_norm": 0.225693017244339,
      "learning_rate": 3.098061410356493e-05,
      "loss": 1.9509,
      "step": 292500
    },
    {
      "epoch": 11.436377829820453,
      "grad_norm": 0.236698180437088,
      "learning_rate": 3.094808743169399e-05,
      "loss": 1.9516,
      "step": 293000
    },
    {
      "epoch": 11.455893832943014,
      "grad_norm": 0.22362084686756134,
      "learning_rate": 3.0915625813166796e-05,
      "loss": 1.9513,
      "step": 293500
    },
    {
      "epoch": 11.475409836065573,
      "grad_norm": 0.23881137371063232,
      "learning_rate": 3.088309914129586e-05,
      "loss": 1.9513,
      "step": 294000
    },
    {
      "epoch": 11.475409836065573,
      "eval_loss": 1.943453311920166,
      "eval_runtime": 191.8472,
      "eval_samples_per_second": 39070.586,
      "eval_steps_per_second": 19.078,
      "step": 294000
    },
    {
      "epoch": 11.494925839188134,
      "grad_norm": 0.2429826557636261,
      "learning_rate": 3.085057246942493e-05,
      "loss": 1.9509,
      "step": 294500
    },
    {
      "epoch": 11.514441842310696,
      "grad_norm": 0.22840307652950287,
      "learning_rate": 3.0818045797554e-05,
      "loss": 1.9507,
      "step": 295000
    },
    {
      "epoch": 11.533957845433255,
      "grad_norm": 0.2417486011981964,
      "learning_rate": 3.0785584179026805e-05,
      "loss": 1.9516,
      "step": 295500
    },
    {
      "epoch": 11.553473848555816,
      "grad_norm": 0.2314903289079666,
      "learning_rate": 3.075305750715587e-05,
      "loss": 1.9503,
      "step": 296000
    },
    {
      "epoch": 11.553473848555816,
      "eval_loss": 1.943444013595581,
      "eval_runtime": 192.9683,
      "eval_samples_per_second": 38843.599,
      "eval_steps_per_second": 18.967,
      "step": 296000
    },
    {
      "epoch": 11.572989851678376,
      "grad_norm": 0.2249681055545807,
      "learning_rate": 3.072053083528493e-05,
      "loss": 1.9511,
      "step": 296500
    },
    {
      "epoch": 11.592505854800937,
      "grad_norm": 0.23720039427280426,
      "learning_rate": 3.0688004163414e-05,
      "loss": 1.9514,
      "step": 297000
    },
    {
      "epoch": 11.612021857923498,
      "grad_norm": 0.23037762939929962,
      "learning_rate": 3.065554254488681e-05,
      "loss": 1.9506,
      "step": 297500
    },
    {
      "epoch": 11.631537861046057,
      "grad_norm": 0.2228558510541916,
      "learning_rate": 3.0623015873015875e-05,
      "loss": 1.9507,
      "step": 298000
    },
    {
      "epoch": 11.631537861046057,
      "eval_loss": 1.943164587020874,
      "eval_runtime": 192.4474,
      "eval_samples_per_second": 38948.742,
      "eval_steps_per_second": 19.018,
      "step": 298000
    },
    {
      "epoch": 11.651053864168619,
      "grad_norm": 0.22412241995334625,
      "learning_rate": 3.059048920114494e-05,
      "loss": 1.951,
      "step": 298500
    },
    {
      "epoch": 11.670569867291178,
      "grad_norm": 0.22705316543579102,
      "learning_rate": 3.0557962529274e-05,
      "loss": 1.9506,
      "step": 299000
    },
    {
      "epoch": 11.69008587041374,
      "grad_norm": 0.22634658217430115,
      "learning_rate": 3.052550091074681e-05,
      "loss": 1.9515,
      "step": 299500
    },
    {
      "epoch": 11.7096018735363,
      "grad_norm": 0.21294523775577545,
      "learning_rate": 3.049297423887588e-05,
      "loss": 1.9507,
      "step": 300000
    },
    {
      "epoch": 11.7096018735363,
      "eval_loss": 1.9432810544967651,
      "eval_runtime": 192.7692,
      "eval_samples_per_second": 38883.719,
      "eval_steps_per_second": 18.986,
      "step": 300000
    },
    {
      "epoch": 11.72911787665886,
      "grad_norm": 0.21467657387256622,
      "learning_rate": 3.0460447567004945e-05,
      "loss": 1.9509,
      "step": 300500
    },
    {
      "epoch": 11.748633879781421,
      "grad_norm": 0.22028771042823792,
      "learning_rate": 3.042792089513401e-05,
      "loss": 1.951,
      "step": 301000
    },
    {
      "epoch": 11.76814988290398,
      "grad_norm": 0.22880634665489197,
      "learning_rate": 3.039545927660682e-05,
      "loss": 1.9508,
      "step": 301500
    },
    {
      "epoch": 11.787665886026542,
      "grad_norm": 0.22563044726848602,
      "learning_rate": 3.0362932604735884e-05,
      "loss": 1.95,
      "step": 302000
    },
    {
      "epoch": 11.787665886026542,
      "eval_loss": 1.9431077241897583,
      "eval_runtime": 193.3658,
      "eval_samples_per_second": 38763.756,
      "eval_steps_per_second": 18.928,
      "step": 302000
    },
    {
      "epoch": 11.807181889149103,
      "grad_norm": 0.23474439978599548,
      "learning_rate": 3.033040593286495e-05,
      "loss": 1.9516,
      "step": 302500
    },
    {
      "epoch": 11.826697892271662,
      "grad_norm": 0.2209382802248001,
      "learning_rate": 3.0297879260994015e-05,
      "loss": 1.9506,
      "step": 303000
    },
    {
      "epoch": 11.846213895394223,
      "grad_norm": 0.2300242781639099,
      "learning_rate": 3.0265417642466826e-05,
      "loss": 1.9505,
      "step": 303500
    },
    {
      "epoch": 11.865729898516785,
      "grad_norm": 0.2291693240404129,
      "learning_rate": 3.023289097059589e-05,
      "loss": 1.9503,
      "step": 304000
    },
    {
      "epoch": 11.865729898516785,
      "eval_loss": 1.9429948329925537,
      "eval_runtime": 192.3884,
      "eval_samples_per_second": 38960.678,
      "eval_steps_per_second": 19.024,
      "step": 304000
    },
    {
      "epoch": 11.885245901639344,
      "grad_norm": 0.223203644156456,
      "learning_rate": 3.0200364298724954e-05,
      "loss": 1.9503,
      "step": 304500
    },
    {
      "epoch": 11.904761904761905,
      "grad_norm": 0.24975274503231049,
      "learning_rate": 3.0167837626854024e-05,
      "loss": 1.9504,
      "step": 305000
    },
    {
      "epoch": 11.924277907884465,
      "grad_norm": 0.2320220172405243,
      "learning_rate": 3.0135376008326832e-05,
      "loss": 1.9512,
      "step": 305500
    },
    {
      "epoch": 11.943793911007026,
      "grad_norm": 0.22701896727085114,
      "learning_rate": 3.0102849336455896e-05,
      "loss": 1.951,
      "step": 306000
    },
    {
      "epoch": 11.943793911007026,
      "eval_loss": 1.9431043863296509,
      "eval_runtime": 193.8384,
      "eval_samples_per_second": 38669.245,
      "eval_steps_per_second": 18.882,
      "step": 306000
    },
    {
      "epoch": 11.963309914129587,
      "grad_norm": 0.2346263825893402,
      "learning_rate": 3.007032266458496e-05,
      "loss": 1.9505,
      "step": 306500
    },
    {
      "epoch": 11.982825917252146,
      "grad_norm": 0.21826109290122986,
      "learning_rate": 3.003779599271403e-05,
      "loss": 1.9512,
      "step": 307000
    },
    {
      "epoch": 12.002341920374707,
      "grad_norm": 0.22555427253246307,
      "learning_rate": 3.0005334374186832e-05,
      "loss": 1.9504,
      "step": 307500
    },
    {
      "epoch": 12.021857923497267,
      "grad_norm": 0.2345409095287323,
      "learning_rate": 2.9972807702315902e-05,
      "loss": 1.9502,
      "step": 308000
    },
    {
      "epoch": 12.021857923497267,
      "eval_loss": 1.9430863857269287,
      "eval_runtime": 192.0254,
      "eval_samples_per_second": 39034.325,
      "eval_steps_per_second": 19.06,
      "step": 308000
    },
    {
      "epoch": 12.041373926619828,
      "grad_norm": 0.2499380111694336,
      "learning_rate": 2.9940281030444966e-05,
      "loss": 1.9505,
      "step": 308500
    },
    {
      "epoch": 12.06088992974239,
      "grad_norm": 0.22445407509803772,
      "learning_rate": 2.990775435857403e-05,
      "loss": 1.9506,
      "step": 309000
    },
    {
      "epoch": 12.080405932864949,
      "grad_norm": 0.2271495908498764,
      "learning_rate": 2.98752276867031e-05,
      "loss": 1.9488,
      "step": 309500
    },
    {
      "epoch": 12.09992193598751,
      "grad_norm": 0.22504591941833496,
      "learning_rate": 2.9842701014832164e-05,
      "loss": 1.9504,
      "step": 310000
    },
    {
      "epoch": 12.09992193598751,
      "eval_loss": 1.942695140838623,
      "eval_runtime": 193.2227,
      "eval_samples_per_second": 38792.455,
      "eval_steps_per_second": 18.942,
      "step": 310000
    },
    {
      "epoch": 12.119437939110071,
      "grad_norm": 0.2308654487133026,
      "learning_rate": 2.9810174342961228e-05,
      "loss": 1.95,
      "step": 310500
    },
    {
      "epoch": 12.13895394223263,
      "grad_norm": 0.2293502241373062,
      "learning_rate": 2.97776476710903e-05,
      "loss": 1.9511,
      "step": 311000
    },
    {
      "epoch": 12.158469945355192,
      "grad_norm": 0.22949403524398804,
      "learning_rate": 2.97451860525631e-05,
      "loss": 1.9498,
      "step": 311500
    },
    {
      "epoch": 12.177985948477751,
      "grad_norm": 0.22642263770103455,
      "learning_rate": 2.971265938069217e-05,
      "loss": 1.9507,
      "step": 312000
    },
    {
      "epoch": 12.177985948477751,
      "eval_loss": 1.942886233329773,
      "eval_runtime": 192.5309,
      "eval_samples_per_second": 38931.85,
      "eval_steps_per_second": 19.01,
      "step": 312000
    },
    {
      "epoch": 12.197501951600312,
      "grad_norm": 0.23525495827198029,
      "learning_rate": 2.9680132708821234e-05,
      "loss": 1.9508,
      "step": 312500
    },
    {
      "epoch": 12.217017954722873,
      "grad_norm": 0.23414355516433716,
      "learning_rate": 2.9647606036950298e-05,
      "loss": 1.9512,
      "step": 313000
    },
    {
      "epoch": 12.236533957845433,
      "grad_norm": 0.22518101334571838,
      "learning_rate": 2.9615144418423106e-05,
      "loss": 1.9502,
      "step": 313500
    },
    {
      "epoch": 12.256049960967994,
      "grad_norm": 0.226345956325531,
      "learning_rate": 2.9582682799895917e-05,
      "loss": 1.9501,
      "step": 314000
    },
    {
      "epoch": 12.256049960967994,
      "eval_loss": 1.942637324333191,
      "eval_runtime": 193.717,
      "eval_samples_per_second": 38693.463,
      "eval_steps_per_second": 18.894,
      "step": 314000
    },
    {
      "epoch": 12.275565964090553,
      "grad_norm": 0.23780162632465363,
      "learning_rate": 2.955015612802498e-05,
      "loss": 1.9504,
      "step": 314500
    },
    {
      "epoch": 12.295081967213115,
      "grad_norm": 0.22840112447738647,
      "learning_rate": 2.951762945615405e-05,
      "loss": 1.9507,
      "step": 315000
    },
    {
      "epoch": 12.314597970335676,
      "grad_norm": 0.2296520173549652,
      "learning_rate": 2.9485102784283116e-05,
      "loss": 1.9506,
      "step": 315500
    },
    {
      "epoch": 12.334113973458235,
      "grad_norm": 0.25350791215896606,
      "learning_rate": 2.945257611241218e-05,
      "loss": 1.9504,
      "step": 316000
    },
    {
      "epoch": 12.334113973458235,
      "eval_loss": 1.9428348541259766,
      "eval_runtime": 192.9935,
      "eval_samples_per_second": 38838.524,
      "eval_steps_per_second": 18.964,
      "step": 316000
    },
    {
      "epoch": 12.353629976580796,
      "grad_norm": 0.23525294661521912,
      "learning_rate": 2.9420049440541247e-05,
      "loss": 1.9507,
      "step": 316500
    },
    {
      "epoch": 12.373145979703358,
      "grad_norm": 0.24101987481117249,
      "learning_rate": 2.938752276867031e-05,
      "loss": 1.9497,
      "step": 317000
    },
    {
      "epoch": 12.392661982825917,
      "grad_norm": 0.22877903282642365,
      "learning_rate": 2.9354996096799374e-05,
      "loss": 1.9501,
      "step": 317500
    },
    {
      "epoch": 12.412177985948478,
      "grad_norm": 0.22171419858932495,
      "learning_rate": 2.9322534478272186e-05,
      "loss": 1.9503,
      "step": 318000
    },
    {
      "epoch": 12.412177985948478,
      "eval_loss": 1.94259512424469,
      "eval_runtime": 194.2891,
      "eval_samples_per_second": 38579.535,
      "eval_steps_per_second": 18.838,
      "step": 318000
    },
    {
      "epoch": 12.431693989071038,
      "grad_norm": 0.21485432982444763,
      "learning_rate": 2.929000780640125e-05,
      "loss": 1.95,
      "step": 318500
    },
    {
      "epoch": 12.451209992193599,
      "grad_norm": 0.21860986948013306,
      "learning_rate": 2.9257481134530317e-05,
      "loss": 1.9503,
      "step": 319000
    },
    {
      "epoch": 12.47072599531616,
      "grad_norm": 0.23206093907356262,
      "learning_rate": 2.922495446265938e-05,
      "loss": 1.9508,
      "step": 319500
    },
    {
      "epoch": 12.49024199843872,
      "grad_norm": 0.2528401017189026,
      "learning_rate": 2.919249284413219e-05,
      "loss": 1.95,
      "step": 320000
    },
    {
      "epoch": 12.49024199843872,
      "eval_loss": 1.9426422119140625,
      "eval_runtime": 192.5782,
      "eval_samples_per_second": 38922.278,
      "eval_steps_per_second": 19.005,
      "step": 320000
    },
    {
      "epoch": 12.50975800156128,
      "grad_norm": 0.20905157923698425,
      "learning_rate": 2.9160031225605e-05,
      "loss": 1.9502,
      "step": 320500
    },
    {
      "epoch": 12.52927400468384,
      "grad_norm": 0.23675715923309326,
      "learning_rate": 2.9127504553734063e-05,
      "loss": 1.95,
      "step": 321000
    },
    {
      "epoch": 12.548790007806401,
      "grad_norm": 0.2228776067495346,
      "learning_rate": 2.9094977881863127e-05,
      "loss": 1.9496,
      "step": 321500
    },
    {
      "epoch": 12.568306010928962,
      "grad_norm": 0.23138493299484253,
      "learning_rate": 2.9062451209992198e-05,
      "loss": 1.9501,
      "step": 322000
    },
    {
      "epoch": 12.568306010928962,
      "eval_loss": 1.9424718618392944,
      "eval_runtime": 192.4579,
      "eval_samples_per_second": 38946.619,
      "eval_steps_per_second": 19.017,
      "step": 322000
    },
    {
      "epoch": 12.587822014051522,
      "grad_norm": 0.21090659499168396,
      "learning_rate": 2.902992453812126e-05,
      "loss": 1.95,
      "step": 322500
    },
    {
      "epoch": 12.607338017174083,
      "grad_norm": 0.24129502475261688,
      "learning_rate": 2.8997397866250325e-05,
      "loss": 1.9502,
      "step": 323000
    },
    {
      "epoch": 12.626854020296644,
      "grad_norm": 0.2164173722267151,
      "learning_rate": 2.8964936247723133e-05,
      "loss": 1.9501,
      "step": 323500
    },
    {
      "epoch": 12.646370023419204,
      "grad_norm": 0.23296722769737244,
      "learning_rate": 2.8932409575852197e-05,
      "loss": 1.9501,
      "step": 324000
    },
    {
      "epoch": 12.646370023419204,
      "eval_loss": 1.9423861503601074,
      "eval_runtime": 192.8735,
      "eval_samples_per_second": 38862.689,
      "eval_steps_per_second": 18.976,
      "step": 324000
    },
    {
      "epoch": 12.665886026541765,
      "grad_norm": 0.22833992540836334,
      "learning_rate": 2.8899882903981268e-05,
      "loss": 1.9497,
      "step": 324500
    },
    {
      "epoch": 12.685402029664324,
      "grad_norm": 0.223353311419487,
      "learning_rate": 2.886735623211033e-05,
      "loss": 1.9501,
      "step": 325000
    },
    {
      "epoch": 12.704918032786885,
      "grad_norm": 0.22117562592029572,
      "learning_rate": 2.8834829560239395e-05,
      "loss": 1.9501,
      "step": 325500
    },
    {
      "epoch": 12.724434035909447,
      "grad_norm": 0.22005988657474518,
      "learning_rate": 2.8802302888368466e-05,
      "loss": 1.9497,
      "step": 326000
    },
    {
      "epoch": 12.724434035909447,
      "eval_loss": 1.942402958869934,
      "eval_runtime": 192.8587,
      "eval_samples_per_second": 38865.667,
      "eval_steps_per_second": 18.978,
      "step": 326000
    },
    {
      "epoch": 12.743950039032006,
      "grad_norm": 0.2555358409881592,
      "learning_rate": 2.876977621649753e-05,
      "loss": 1.9499,
      "step": 326500
    },
    {
      "epoch": 12.763466042154567,
      "grad_norm": 0.2267152965068817,
      "learning_rate": 2.8737249544626594e-05,
      "loss": 1.9494,
      "step": 327000
    },
    {
      "epoch": 12.782982045277127,
      "grad_norm": 0.21412284672260284,
      "learning_rate": 2.87047879260994e-05,
      "loss": 1.9503,
      "step": 327500
    },
    {
      "epoch": 12.802498048399688,
      "grad_norm": 0.2274446189403534,
      "learning_rate": 2.8672261254228465e-05,
      "loss": 1.95,
      "step": 328000
    },
    {
      "epoch": 12.802498048399688,
      "eval_loss": 1.9422345161437988,
      "eval_runtime": 193.8326,
      "eval_samples_per_second": 38670.391,
      "eval_steps_per_second": 18.882,
      "step": 328000
    },
    {
      "epoch": 12.822014051522249,
      "grad_norm": 0.21657252311706543,
      "learning_rate": 2.8639734582357536e-05,
      "loss": 1.9503,
      "step": 328500
    },
    {
      "epoch": 12.841530054644808,
      "grad_norm": 0.2509935796260834,
      "learning_rate": 2.8607272963830344e-05,
      "loss": 1.9502,
      "step": 329000
    },
    {
      "epoch": 12.86104605776737,
      "grad_norm": 0.2518555223941803,
      "learning_rate": 2.8574746291959408e-05,
      "loss": 1.95,
      "step": 329500
    },
    {
      "epoch": 12.880562060889929,
      "grad_norm": 0.21907755732536316,
      "learning_rate": 2.854221962008847e-05,
      "loss": 1.9495,
      "step": 330000
    },
    {
      "epoch": 12.880562060889929,
      "eval_loss": 1.9422334432601929,
      "eval_runtime": 193.0684,
      "eval_samples_per_second": 38823.462,
      "eval_steps_per_second": 18.957,
      "step": 330000
    },
    {
      "epoch": 12.90007806401249,
      "grad_norm": 0.22538906335830688,
      "learning_rate": 2.8509692948217542e-05,
      "loss": 1.95,
      "step": 330500
    },
    {
      "epoch": 12.919594067135051,
      "grad_norm": 0.22501669824123383,
      "learning_rate": 2.8477166276346606e-05,
      "loss": 1.9495,
      "step": 331000
    },
    {
      "epoch": 12.93911007025761,
      "grad_norm": 0.22958749532699585,
      "learning_rate": 2.844463960447567e-05,
      "loss": 1.9499,
      "step": 331500
    },
    {
      "epoch": 12.958626073380172,
      "grad_norm": 0.23111188411712646,
      "learning_rate": 2.841211293260474e-05,
      "loss": 1.9501,
      "step": 332000
    },
    {
      "epoch": 12.958626073380172,
      "eval_loss": 1.9421061277389526,
      "eval_runtime": 195.0251,
      "eval_samples_per_second": 38433.949,
      "eval_steps_per_second": 18.767,
      "step": 332000
    },
    {
      "epoch": 12.978142076502731,
      "grad_norm": 0.25300630927085876,
      "learning_rate": 2.8379586260733804e-05,
      "loss": 1.9498,
      "step": 332500
    },
    {
      "epoch": 12.997658079625293,
      "grad_norm": 0.2227044701576233,
      "learning_rate": 2.8347124642206612e-05,
      "loss": 1.95,
      "step": 333000
    },
    {
      "epoch": 13.017174082747854,
      "grad_norm": 0.23031578958034515,
      "learning_rate": 2.8314597970335676e-05,
      "loss": 1.9494,
      "step": 333500
    },
    {
      "epoch": 13.036690085870413,
      "grad_norm": 0.22550567984580994,
      "learning_rate": 2.8282136351808487e-05,
      "loss": 1.9495,
      "step": 334000
    },
    {
      "epoch": 13.036690085870413,
      "eval_loss": 1.9421600103378296,
      "eval_runtime": 193.477,
      "eval_samples_per_second": 38741.476,
      "eval_steps_per_second": 18.917,
      "step": 334000
    },
    {
      "epoch": 13.056206088992974,
      "grad_norm": 0.2217400074005127,
      "learning_rate": 2.824960967993755e-05,
      "loss": 1.95,
      "step": 334500
    },
    {
      "epoch": 13.075722092115535,
      "grad_norm": 0.22232234477996826,
      "learning_rate": 2.8217083008066615e-05,
      "loss": 1.9493,
      "step": 335000
    },
    {
      "epoch": 13.095238095238095,
      "grad_norm": 0.23964402079582214,
      "learning_rate": 2.8184556336195682e-05,
      "loss": 1.9494,
      "step": 335500
    },
    {
      "epoch": 13.114754098360656,
      "grad_norm": 0.23576049506664276,
      "learning_rate": 2.8152029664324746e-05,
      "loss": 1.9499,
      "step": 336000
    },
    {
      "epoch": 13.114754098360656,
      "eval_loss": 1.9420454502105713,
      "eval_runtime": 196.5366,
      "eval_samples_per_second": 38138.355,
      "eval_steps_per_second": 18.622,
      "step": 336000
    },
    {
      "epoch": 13.134270101483215,
      "grad_norm": 0.210781529545784,
      "learning_rate": 2.8119568045797557e-05,
      "loss": 1.9499,
      "step": 336500
    },
    {
      "epoch": 13.153786104605777,
      "grad_norm": 0.22257786989212036,
      "learning_rate": 2.808704137392662e-05,
      "loss": 1.9491,
      "step": 337000
    },
    {
      "epoch": 13.173302107728338,
      "grad_norm": 0.22631339728832245,
      "learning_rate": 2.805451470205569e-05,
      "loss": 1.9496,
      "step": 337500
    },
    {
      "epoch": 13.192818110850897,
      "grad_norm": 0.21965233981609344,
      "learning_rate": 2.8021988030184755e-05,
      "loss": 1.9502,
      "step": 338000
    },
    {
      "epoch": 13.192818110850897,
      "eval_loss": 1.942010521888733,
      "eval_runtime": 193.8451,
      "eval_samples_per_second": 38667.9,
      "eval_steps_per_second": 18.881,
      "step": 338000
    },
    {
      "epoch": 13.212334113973458,
      "grad_norm": 0.2229016274213791,
      "learning_rate": 2.798946135831382e-05,
      "loss": 1.9494,
      "step": 338500
    },
    {
      "epoch": 13.231850117096018,
      "grad_norm": 0.22457610070705414,
      "learning_rate": 2.7956934686442886e-05,
      "loss": 1.9498,
      "step": 339000
    },
    {
      "epoch": 13.251366120218579,
      "grad_norm": 0.22996225953102112,
      "learning_rate": 2.792447306791569e-05,
      "loss": 1.9493,
      "step": 339500
    },
    {
      "epoch": 13.27088212334114,
      "grad_norm": 0.2335006594657898,
      "learning_rate": 2.789194639604476e-05,
      "loss": 1.9497,
      "step": 340000
    },
    {
      "epoch": 13.27088212334114,
      "eval_loss": 1.9419574737548828,
      "eval_runtime": 195.9345,
      "eval_samples_per_second": 38255.546,
      "eval_steps_per_second": 18.68,
      "step": 340000
    },
    {
      "epoch": 13.2903981264637,
      "grad_norm": 0.21649378538131714,
      "learning_rate": 2.7859419724173825e-05,
      "loss": 1.9496,
      "step": 340500
    },
    {
      "epoch": 13.30991412958626,
      "grad_norm": 0.22195635735988617,
      "learning_rate": 2.782689305230289e-05,
      "loss": 1.9496,
      "step": 341000
    },
    {
      "epoch": 13.329430132708822,
      "grad_norm": 0.21942457556724548,
      "learning_rate": 2.7794366380431956e-05,
      "loss": 1.9494,
      "step": 341500
    },
    {
      "epoch": 13.348946135831381,
      "grad_norm": 0.23228414356708527,
      "learning_rate": 2.776183970856102e-05,
      "loss": 1.9496,
      "step": 342000
    },
    {
      "epoch": 13.348946135831381,
      "eval_loss": 1.9419578313827515,
      "eval_runtime": 193.7951,
      "eval_samples_per_second": 38677.873,
      "eval_steps_per_second": 18.886,
      "step": 342000
    },
    {
      "epoch": 13.368462138953943,
      "grad_norm": 0.21974603831768036,
      "learning_rate": 2.7729313036690087e-05,
      "loss": 1.95,
      "step": 342500
    },
    {
      "epoch": 13.387978142076502,
      "grad_norm": 0.23172619938850403,
      "learning_rate": 2.7696786364819154e-05,
      "loss": 1.9493,
      "step": 343000
    },
    {
      "epoch": 13.407494145199063,
      "grad_norm": 0.2251078337430954,
      "learning_rate": 2.766432474629196e-05,
      "loss": 1.9491,
      "step": 343500
    },
    {
      "epoch": 13.427010148321624,
      "grad_norm": 0.24114708602428436,
      "learning_rate": 2.763179807442103e-05,
      "loss": 1.9499,
      "step": 344000
    },
    {
      "epoch": 13.427010148321624,
      "eval_loss": 1.9417437314987183,
      "eval_runtime": 195.9685,
      "eval_samples_per_second": 38248.926,
      "eval_steps_per_second": 18.676,
      "step": 344000
    },
    {
      "epoch": 13.446526151444184,
      "grad_norm": 0.2281612753868103,
      "learning_rate": 2.7599271402550093e-05,
      "loss": 1.9491,
      "step": 344500
    },
    {
      "epoch": 13.466042154566745,
      "grad_norm": 0.23981085419654846,
      "learning_rate": 2.75668097840229e-05,
      "loss": 1.9495,
      "step": 345000
    },
    {
      "epoch": 13.485558157689304,
      "grad_norm": 0.23762094974517822,
      "learning_rate": 2.7534283112151965e-05,
      "loss": 1.949,
      "step": 345500
    },
    {
      "epoch": 13.505074160811866,
      "grad_norm": 0.23227819800376892,
      "learning_rate": 2.750175644028103e-05,
      "loss": 1.9496,
      "step": 346000
    },
    {
      "epoch": 13.505074160811866,
      "eval_loss": 1.941719889640808,
      "eval_runtime": 193.6987,
      "eval_samples_per_second": 38697.128,
      "eval_steps_per_second": 18.895,
      "step": 346000
    },
    {
      "epoch": 13.524590163934427,
      "grad_norm": 0.22588062286376953,
      "learning_rate": 2.74692297684101e-05,
      "loss": 1.9499,
      "step": 346500
    },
    {
      "epoch": 13.544106167056986,
      "grad_norm": 0.2232944667339325,
      "learning_rate": 2.7436703096539163e-05,
      "loss": 1.9493,
      "step": 347000
    },
    {
      "epoch": 13.563622170179547,
      "grad_norm": 0.22636251151561737,
      "learning_rate": 2.740417642466823e-05,
      "loss": 1.9495,
      "step": 347500
    },
    {
      "epoch": 13.583138173302107,
      "grad_norm": 0.21668300032615662,
      "learning_rate": 2.7371649752797298e-05,
      "loss": 1.949,
      "step": 348000
    },
    {
      "epoch": 13.583138173302107,
      "eval_loss": 1.9416412115097046,
      "eval_runtime": 194.2801,
      "eval_samples_per_second": 38581.323,
      "eval_steps_per_second": 18.839,
      "step": 348000
    },
    {
      "epoch": 13.602654176424668,
      "grad_norm": 0.21811652183532715,
      "learning_rate": 2.7339188134270106e-05,
      "loss": 1.9489,
      "step": 348500
    },
    {
      "epoch": 13.62217017954723,
      "grad_norm": 0.23298950493335724,
      "learning_rate": 2.730666146239917e-05,
      "loss": 1.949,
      "step": 349000
    },
    {
      "epoch": 13.641686182669789,
      "grad_norm": 0.23779284954071045,
      "learning_rate": 2.7274134790528233e-05,
      "loss": 1.9498,
      "step": 349500
    },
    {
      "epoch": 13.66120218579235,
      "grad_norm": 0.2240687608718872,
      "learning_rate": 2.7241608118657304e-05,
      "loss": 1.9495,
      "step": 350000
    },
    {
      "epoch": 13.66120218579235,
      "eval_loss": 1.9415645599365234,
      "eval_runtime": 194.6166,
      "eval_samples_per_second": 38514.606,
      "eval_steps_per_second": 18.806,
      "step": 350000
    },
    {
      "epoch": 13.680718188914911,
      "grad_norm": 0.23428203165531158,
      "learning_rate": 2.7209081446786368e-05,
      "loss": 1.9492,
      "step": 350500
    },
    {
      "epoch": 13.70023419203747,
      "grad_norm": 0.2327020913362503,
      "learning_rate": 2.7176619828259175e-05,
      "loss": 1.9501,
      "step": 351000
    },
    {
      "epoch": 13.719750195160032,
      "grad_norm": 0.22978591918945312,
      "learning_rate": 2.714409315638824e-05,
      "loss": 1.9486,
      "step": 351500
    },
    {
      "epoch": 13.739266198282591,
      "grad_norm": 0.2277509719133377,
      "learning_rate": 2.7111566484517303e-05,
      "loss": 1.9494,
      "step": 352000
    },
    {
      "epoch": 13.739266198282591,
      "eval_loss": 1.941608190536499,
      "eval_runtime": 194.199,
      "eval_samples_per_second": 38597.438,
      "eval_steps_per_second": 18.847,
      "step": 352000
    },
    {
      "epoch": 13.758782201405152,
      "grad_norm": 0.22410927712917328,
      "learning_rate": 2.7079039812646374e-05,
      "loss": 1.9498,
      "step": 352500
    },
    {
      "epoch": 13.778298204527713,
      "grad_norm": 0.22014999389648438,
      "learning_rate": 2.7046513140775437e-05,
      "loss": 1.9493,
      "step": 353000
    },
    {
      "epoch": 13.797814207650273,
      "grad_norm": 0.2554019093513489,
      "learning_rate": 2.7014051522248245e-05,
      "loss": 1.9493,
      "step": 353500
    },
    {
      "epoch": 13.817330210772834,
      "grad_norm": 0.21959814429283142,
      "learning_rate": 2.698152485037731e-05,
      "loss": 1.949,
      "step": 354000
    },
    {
      "epoch": 13.817330210772834,
      "eval_loss": 1.9415472745895386,
      "eval_runtime": 196.8826,
      "eval_samples_per_second": 38071.325,
      "eval_steps_per_second": 18.59,
      "step": 354000
    },
    {
      "epoch": 13.836846213895395,
      "grad_norm": 0.21283310651779175,
      "learning_rate": 2.6948998178506373e-05,
      "loss": 1.9492,
      "step": 354500
    },
    {
      "epoch": 13.856362217017955,
      "grad_norm": 0.22281479835510254,
      "learning_rate": 2.6916471506635444e-05,
      "loss": 1.9489,
      "step": 355000
    },
    {
      "epoch": 13.875878220140516,
      "grad_norm": 0.22832371294498444,
      "learning_rate": 2.6883944834764507e-05,
      "loss": 1.9488,
      "step": 355500
    },
    {
      "epoch": 13.895394223263075,
      "grad_norm": 0.22527214884757996,
      "learning_rate": 2.6851483216237315e-05,
      "loss": 1.9489,
      "step": 356000
    },
    {
      "epoch": 13.895394223263075,
      "eval_loss": 1.941377878189087,
      "eval_runtime": 194.2977,
      "eval_samples_per_second": 38577.817,
      "eval_steps_per_second": 18.837,
      "step": 356000
    },
    {
      "epoch": 13.914910226385636,
      "grad_norm": 0.2338230460882187,
      "learning_rate": 2.681895654436638e-05,
      "loss": 1.9493,
      "step": 356500
    },
    {
      "epoch": 13.934426229508198,
      "grad_norm": 0.22212940454483032,
      "learning_rate": 2.678642987249545e-05,
      "loss": 1.9494,
      "step": 357000
    },
    {
      "epoch": 13.953942232630757,
      "grad_norm": 0.21991577744483948,
      "learning_rate": 2.6753903200624514e-05,
      "loss": 1.9487,
      "step": 357500
    },
    {
      "epoch": 13.973458235753318,
      "grad_norm": 0.21679028868675232,
      "learning_rate": 2.6721376528753577e-05,
      "loss": 1.9495,
      "step": 358000
    },
    {
      "epoch": 13.973458235753318,
      "eval_loss": 1.9413758516311646,
      "eval_runtime": 197.9462,
      "eval_samples_per_second": 37866.774,
      "eval_steps_per_second": 18.49,
      "step": 358000
    },
    {
      "epoch": 13.992974238875878,
      "grad_norm": 0.2214234173297882,
      "learning_rate": 2.6688849856882648e-05,
      "loss": 1.9492,
      "step": 358500
    },
    {
      "epoch": 14.012490241998439,
      "grad_norm": 0.22871655225753784,
      "learning_rate": 2.6656323185011712e-05,
      "loss": 1.949,
      "step": 359000
    },
    {
      "epoch": 14.032006245121,
      "grad_norm": 0.21488071978092194,
      "learning_rate": 2.662386156648452e-05,
      "loss": 1.948,
      "step": 359500
    },
    {
      "epoch": 14.05152224824356,
      "grad_norm": 0.22966867685317993,
      "learning_rate": 2.6591334894613583e-05,
      "loss": 1.9492,
      "step": 360000
    },
    {
      "epoch": 14.05152224824356,
      "eval_loss": 1.9411661624908447,
      "eval_runtime": 194.8115,
      "eval_samples_per_second": 38476.08,
      "eval_steps_per_second": 18.787,
      "step": 360000
    },
    {
      "epoch": 14.07103825136612,
      "grad_norm": 0.23680835962295532,
      "learning_rate": 2.6558808222742647e-05,
      "loss": 1.9489,
      "step": 360500
    },
    {
      "epoch": 14.09055425448868,
      "grad_norm": 0.23865875601768494,
      "learning_rate": 2.6526281550871718e-05,
      "loss": 1.9485,
      "step": 361000
    },
    {
      "epoch": 14.110070257611241,
      "grad_norm": 0.22096051275730133,
      "learning_rate": 2.649375487900078e-05,
      "loss": 1.9482,
      "step": 361500
    },
    {
      "epoch": 14.129586260733802,
      "grad_norm": 0.22634921967983246,
      "learning_rate": 2.6461228207129845e-05,
      "loss": 1.9487,
      "step": 362000
    },
    {
      "epoch": 14.129586260733802,
      "eval_loss": 1.9412546157836914,
      "eval_runtime": 196.4824,
      "eval_samples_per_second": 38148.879,
      "eval_steps_per_second": 18.628,
      "step": 362000
    },
    {
      "epoch": 14.149102263856362,
      "grad_norm": 0.23836301267147064,
      "learning_rate": 2.6428701535258916e-05,
      "loss": 1.9489,
      "step": 362500
    },
    {
      "epoch": 14.168618266978923,
      "grad_norm": 0.2142157256603241,
      "learning_rate": 2.639617486338798e-05,
      "loss": 1.9485,
      "step": 363000
    },
    {
      "epoch": 14.188134270101482,
      "grad_norm": 0.2172747254371643,
      "learning_rate": 2.6363713244860788e-05,
      "loss": 1.9484,
      "step": 363500
    },
    {
      "epoch": 14.207650273224044,
      "grad_norm": 0.23735709488391876,
      "learning_rate": 2.633118657298985e-05,
      "loss": 1.9491,
      "step": 364000
    },
    {
      "epoch": 14.207650273224044,
      "eval_loss": 1.94129478931427,
      "eval_runtime": 194.2115,
      "eval_samples_per_second": 38594.958,
      "eval_steps_per_second": 18.845,
      "step": 364000
    },
    {
      "epoch": 14.227166276346605,
      "grad_norm": 0.2196311056613922,
      "learning_rate": 2.6298724954462663e-05,
      "loss": 1.9486,
      "step": 364500
    },
    {
      "epoch": 14.246682279469164,
      "grad_norm": 0.2124887853860855,
      "learning_rate": 2.6266198282591727e-05,
      "loss": 1.9482,
      "step": 365000
    },
    {
      "epoch": 14.266198282591725,
      "grad_norm": 0.22559086978435516,
      "learning_rate": 2.6233671610720794e-05,
      "loss": 1.9488,
      "step": 365500
    },
    {
      "epoch": 14.285714285714286,
      "grad_norm": 0.22262702882289886,
      "learning_rate": 2.6201144938849858e-05,
      "loss": 1.9489,
      "step": 366000
    },
    {
      "epoch": 14.285714285714286,
      "eval_loss": 1.9411331415176392,
      "eval_runtime": 194.4278,
      "eval_samples_per_second": 38552.011,
      "eval_steps_per_second": 18.824,
      "step": 366000
    },
    {
      "epoch": 14.305230288836846,
      "grad_norm": 0.24011509120464325,
      "learning_rate": 2.616868332032267e-05,
      "loss": 1.9485,
      "step": 366500
    },
    {
      "epoch": 14.324746291959407,
      "grad_norm": 0.23143133521080017,
      "learning_rate": 2.6136156648451733e-05,
      "loss": 1.9483,
      "step": 367000
    },
    {
      "epoch": 14.344262295081966,
      "grad_norm": 0.23828096687793732,
      "learning_rate": 2.6103629976580797e-05,
      "loss": 1.9488,
      "step": 367500
    },
    {
      "epoch": 14.363778298204528,
      "grad_norm": 0.23163391649723053,
      "learning_rate": 2.6071103304709864e-05,
      "loss": 1.9484,
      "step": 368000
    },
    {
      "epoch": 14.363778298204528,
      "eval_loss": 1.9411088228225708,
      "eval_runtime": 196.692,
      "eval_samples_per_second": 38108.227,
      "eval_steps_per_second": 18.608,
      "step": 368000
    },
    {
      "epoch": 14.383294301327089,
      "grad_norm": 0.2407095581293106,
      "learning_rate": 2.6038576632838928e-05,
      "loss": 1.9481,
      "step": 368500
    },
    {
      "epoch": 14.402810304449648,
      "grad_norm": 0.22519569098949432,
      "learning_rate": 2.600611501431174e-05,
      "loss": 1.9485,
      "step": 369000
    },
    {
      "epoch": 14.42232630757221,
      "grad_norm": 0.22043268382549286,
      "learning_rate": 2.5973588342440803e-05,
      "loss": 1.9489,
      "step": 369500
    },
    {
      "epoch": 14.441842310694769,
      "grad_norm": 0.237044557929039,
      "learning_rate": 2.5941061670569867e-05,
      "loss": 1.9489,
      "step": 370000
    },
    {
      "epoch": 14.441842310694769,
      "eval_loss": 1.941082239151001,
      "eval_runtime": 194.6263,
      "eval_samples_per_second": 38512.7,
      "eval_steps_per_second": 18.805,
      "step": 370000
    },
    {
      "epoch": 14.46135831381733,
      "grad_norm": 0.21682262420654297,
      "learning_rate": 2.5908534998698937e-05,
      "loss": 1.9491,
      "step": 370500
    },
    {
      "epoch": 14.480874316939891,
      "grad_norm": 0.22455468773841858,
      "learning_rate": 2.5876008326828e-05,
      "loss": 1.9479,
      "step": 371000
    },
    {
      "epoch": 14.50039032006245,
      "grad_norm": 0.2289542853832245,
      "learning_rate": 2.5843481654957065e-05,
      "loss": 1.9494,
      "step": 371500
    },
    {
      "epoch": 14.519906323185012,
      "grad_norm": 0.2413673996925354,
      "learning_rate": 2.5810954983086132e-05,
      "loss": 1.9491,
      "step": 372000
    },
    {
      "epoch": 14.519906323185012,
      "eval_loss": 1.941030502319336,
      "eval_runtime": 197.5208,
      "eval_samples_per_second": 37948.317,
      "eval_steps_per_second": 18.53,
      "step": 372000
    },
    {
      "epoch": 14.539422326307573,
      "grad_norm": 0.21725192666053772,
      "learning_rate": 2.5778428311215196e-05,
      "loss": 1.949,
      "step": 372500
    },
    {
      "epoch": 14.558938329430132,
      "grad_norm": 0.2241104543209076,
      "learning_rate": 2.5745966692688007e-05,
      "loss": 1.9488,
      "step": 373000
    },
    {
      "epoch": 14.578454332552694,
      "grad_norm": 0.21667927503585815,
      "learning_rate": 2.571344002081707e-05,
      "loss": 1.9486,
      "step": 373500
    },
    {
      "epoch": 14.597970335675253,
      "grad_norm": 0.23796266317367554,
      "learning_rate": 2.5680913348946138e-05,
      "loss": 1.9478,
      "step": 374000
    },
    {
      "epoch": 14.597970335675253,
      "eval_loss": 1.9409785270690918,
      "eval_runtime": 193.7867,
      "eval_samples_per_second": 38679.562,
      "eval_steps_per_second": 18.887,
      "step": 374000
    },
    {
      "epoch": 14.617486338797814,
      "grad_norm": 0.22357696294784546,
      "learning_rate": 2.5648386677075202e-05,
      "loss": 1.9483,
      "step": 374500
    },
    {
      "epoch": 14.637002341920375,
      "grad_norm": 0.23492209613323212,
      "learning_rate": 2.5615925058548013e-05,
      "loss": 1.9487,
      "step": 375000
    },
    {
      "epoch": 14.656518345042935,
      "grad_norm": 0.22514961659908295,
      "learning_rate": 2.5583398386677077e-05,
      "loss": 1.9481,
      "step": 375500
    },
    {
      "epoch": 14.676034348165496,
      "grad_norm": 0.22779493033885956,
      "learning_rate": 2.555087171480614e-05,
      "loss": 1.9482,
      "step": 376000
    },
    {
      "epoch": 14.676034348165496,
      "eval_loss": 1.9408448934555054,
      "eval_runtime": 194.7367,
      "eval_samples_per_second": 38490.867,
      "eval_steps_per_second": 18.795,
      "step": 376000
    },
    {
      "epoch": 14.695550351288055,
      "grad_norm": 0.24714058637619019,
      "learning_rate": 2.551834504293521e-05,
      "loss": 1.9479,
      "step": 376500
    },
    {
      "epoch": 14.715066354410617,
      "grad_norm": 0.23945048451423645,
      "learning_rate": 2.5485883424408013e-05,
      "loss": 1.9489,
      "step": 377000
    },
    {
      "epoch": 14.734582357533178,
      "grad_norm": 0.22110827267169952,
      "learning_rate": 2.5453356752537083e-05,
      "loss": 1.9483,
      "step": 377500
    },
    {
      "epoch": 14.754098360655737,
      "grad_norm": 0.23162266612052917,
      "learning_rate": 2.5420830080666147e-05,
      "loss": 1.9486,
      "step": 378000
    },
    {
      "epoch": 14.754098360655737,
      "eval_loss": 1.940881609916687,
      "eval_runtime": 194.6521,
      "eval_samples_per_second": 38507.596,
      "eval_steps_per_second": 18.803,
      "step": 378000
    },
    {
      "epoch": 14.773614363778298,
      "grad_norm": 0.23774933815002441,
      "learning_rate": 2.538830340879521e-05,
      "loss": 1.9486,
      "step": 378500
    },
    {
      "epoch": 14.793130366900858,
      "grad_norm": 0.22300980985164642,
      "learning_rate": 2.535584179026802e-05,
      "loss": 1.9484,
      "step": 379000
    },
    {
      "epoch": 14.812646370023419,
      "grad_norm": 0.2375689148902893,
      "learning_rate": 2.532338017174083e-05,
      "loss": 1.9476,
      "step": 379500
    },
    {
      "epoch": 14.83216237314598,
      "grad_norm": 0.22309759259223938,
      "learning_rate": 2.5290853499869894e-05,
      "loss": 1.949,
      "step": 380000
    },
    {
      "epoch": 14.83216237314598,
      "eval_loss": 1.9406275749206543,
      "eval_runtime": 194.0696,
      "eval_samples_per_second": 38623.161,
      "eval_steps_per_second": 18.859,
      "step": 380000
    },
    {
      "epoch": 14.85167837626854,
      "grad_norm": 0.24181868135929108,
      "learning_rate": 2.525832682799896e-05,
      "loss": 1.9487,
      "step": 380500
    },
    {
      "epoch": 14.8711943793911,
      "grad_norm": 0.22210431098937988,
      "learning_rate": 2.5225800156128028e-05,
      "loss": 1.9488,
      "step": 381000
    },
    {
      "epoch": 14.890710382513662,
      "grad_norm": 0.21755006909370422,
      "learning_rate": 2.5193273484257092e-05,
      "loss": 1.9483,
      "step": 381500
    },
    {
      "epoch": 14.910226385636221,
      "grad_norm": 0.22085468471050262,
      "learning_rate": 2.516074681238616e-05,
      "loss": 1.9487,
      "step": 382000
    },
    {
      "epoch": 14.910226385636221,
      "eval_loss": 1.9408284425735474,
      "eval_runtime": 198.3393,
      "eval_samples_per_second": 37791.727,
      "eval_steps_per_second": 18.453,
      "step": 382000
    },
    {
      "epoch": 14.929742388758783,
      "grad_norm": 0.21529445052146912,
      "learning_rate": 2.5128285193858964e-05,
      "loss": 1.9484,
      "step": 382500
    },
    {
      "epoch": 14.949258391881342,
      "grad_norm": 0.23579041659832,
      "learning_rate": 2.5095758521988034e-05,
      "loss": 1.9473,
      "step": 383000
    },
    {
      "epoch": 14.968774395003903,
      "grad_norm": 0.25059399008750916,
      "learning_rate": 2.5063231850117098e-05,
      "loss": 1.9487,
      "step": 383500
    },
    {
      "epoch": 14.988290398126464,
      "grad_norm": 0.2139521986246109,
      "learning_rate": 2.5030705178246162e-05,
      "loss": 1.9483,
      "step": 384000
    },
    {
      "epoch": 14.988290398126464,
      "eval_loss": 1.9406269788742065,
      "eval_runtime": 194.1232,
      "eval_samples_per_second": 38612.502,
      "eval_steps_per_second": 18.854,
      "step": 384000
    }
  ],
  "logging_steps": 500,
  "max_steps": 768600,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 30,
  "save_steps": 6000,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.143596599517905e+18,
  "train_batch_size": 512,
  "trial_name": null,
  "trial_params": null
}
